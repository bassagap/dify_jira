app:
  description: ''
  icon: üó®Ô∏è
  icon_background: '#D3F8DF'
  mode: advanced-chat
  name: QAI+
  use_icon_as_answer_icon: true
dependencies:
- current_identifier: null
  type: marketplace
  value:
    marketplace_plugin_unique_identifier: langgenius/azure_openai:0.0.16@1682aad1aec4618e5e7a12d6c327f9d14575405dd80961bf40c4e7cbda06919b
kind: app
version: 0.3.0
workflow:
  conversation_variables:
  - description: Memory for the project issues in the chat
    id: 9c114d69-fb63-42fd-ba11-26b204a5932b
    name: issues_memory
    selector:
    - conversation
    - issues_memory
    value: ''
    value_type: string
  - description: Json string with the issues and linked test cases
    id: bb011083-7a21-4052-bcdb-3b47ff3db99a
    name: linked_test_cases
    selector:
    - conversation
    - linked_test_cases
    value: ''
    value_type: string
  - description: Test cases pending for confirmation
    id: 163be9e5-e5d0-43c5-853b-2762f861a875
    name: tc_to_confirm
    selector:
    - conversation
    - tc_to_confirm
    value: ''
    value_type: string
  - description: what is the current conversation about
    id: 4d1ea68b-cfaa-40c3-9caf-39381e3fa945
    name: topic
    selector:
    - conversation
    - topic
    value: ''
    value_type: string
  - description: Last mentioned issue key in the chat
    id: c131534a-f618-430c-b6bf-4776dbe53ecc
    name: last_issue_key
    selector:
    - conversation
    - last_issue_key
    value: ''
    value_type: string
  - description: Project description and suggested testing tool storage
    id: 79df25d9-24eb-4355-8e3d-6663c04bc0cf
    name: project_testing_tool
    selector:
    - conversation
    - project_testing_tool
    value: []
    value_type: array[object]
  - description: collection of generated test cases
    id: ffd17e48-82ce-44fd-b943-de5f470d5ce8
    name: issue_test_case_memory
    selector:
    - conversation
    - issue_test_case_memory
    value: ''
    value_type: string
  - description: Chat conversation memory
    id: 1048ad91-c4cd-41e9-9748-6b6a67cafc32
    name: conversation_history
    selector:
    - conversation
    - conversation_history
    value: ''
    value_type: string
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_size_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: 'Hi, I''m QAI, your friendly testing assistant. I can help
      you with a variety of testing-related tasks, such as:


      - Answering your questions about software testing

      - Providing guidance on how to improve your testing skills

      - Helping you find the right testing tools and resources

      - Generating test cases and test data

      - Analyzing your test results


      I''m still in development, but I''m learning more every day. I''m eager to help
      you with your testing needs, so please don''t hesitate to ask me anything.


      Here are some examples of how I can help you:

      ‚Äé '
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions:
    - What are the best practices for test automation?
    - How can I test my web app that is within EDP?
    - What are some common software testing tools?
    - Can you help me generate test cases for the issue ....
    suggested_questions_after_answer:
      enabled: true
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 17284821069490-source-1728510367842-target
      selected: false
      source: '17284821069490'
      sourceHandle: source
      target: '1728510367842'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: knowledge-retrieval
        targetType: llm
      id: 1728976442829-source-17284821069490-target
      selected: false
      source: '1728976442829'
      sourceHandle: source
      target: '17284821069490'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1729605116566-source-1729605693354-target
      selected: false
      source: '1729605116566'
      sourceHandle: source
      target: '1729605693354'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1747154882852-source-1728510314302-target
      selected: false
      source: '1747154882852'
      sourceHandle: source
      target: '1728510314302'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1747637812528-source-1747217976454-target
      selected: false
      source: '1747637812528'
      sourceHandle: source
      target: '1747217976454'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 17476431832980-source-1747643513667-target
      selected: false
      source: '17476431832980'
      sourceHandle: source
      target: '1747643513667'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: 1747847182578-false-1747847559679-target
      selected: false
      source: '1747847182578'
      sourceHandle: 'false'
      target: '1747847559679'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: http-request
        targetType: llm
      id: 1747847198692-source-1747847933408-target
      selected: false
      source: '1747847198692'
      sourceHandle: source
      target: '1747847933408'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1747847933408-source-1747848005625-target
      selected: false
      source: '1747847933408'
      sourceHandle: source
      target: '1747848005625'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1747847559679-source-1747850295446-target
      selected: false
      source: '1747847559679'
      sourceHandle: source
      target: '1747850295446'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: answer
      id: 1747926732732-source-1747927766270-target
      selected: false
      source: '1747926732732'
      sourceHandle: source
      target: '1747927766270'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: http-request
        targetType: code
      id: 1747926499875-source-1747928529286-target
      selected: false
      source: '1747926499875'
      sourceHandle: source
      target: '1747928529286'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1747928330892-false-1747926732732-target
      selected: false
      source: '1747928330892'
      sourceHandle: 'false'
      target: '1747926732732'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: knowledge-retrieval
        targetType: if-else
      id: 1747637803226-source-1747852302994-target
      selected: false
      source: '1747637803226'
      sourceHandle: source
      target: '1747852302994'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1747928330892-true-1747637812528-target
      selected: false
      source: '1747928330892'
      sourceHandle: 'true'
      target: '1747637812528'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: llm
      id: 1747637812528-source-1747836694673-target
      selected: false
      source: '1747637812528'
      sourceHandle: source
      target: '1747836694673'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: parameter-extractor
        targetType: code
      id: 1728897364588-source-1747988309822-target
      selected: false
      source: '1728897364588'
      sourceHandle: source
      target: '1747988309822'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 1747988309822-source-1747935981173-target
      selected: false
      source: '1747988309822'
      sourceHandle: source
      target: '1747935981173'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: llm
      id: 1747988309822-source-1729605116566-target
      selected: false
      source: '1747988309822'
      sourceHandle: source
      target: '1729605116566'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: code
      id: 1747928330892-false-1748262440240-target
      selected: false
      source: '1747928330892'
      sourceHandle: 'false'
      target: '1748262440240'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1747643138866-3e5a0114-f4fa-43d9-9c8c-bf6132075d3d-17476431832980-target
      selected: false
      source: '1747643138866'
      sourceHandle: 3e5a0114-f4fa-43d9-9c8c-bf6132075d3d
      target: '17476431832980'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: parameter-extractor
        targetType: if-else
      id: 1747642317265-source-1748329902169-target
      selected: false
      source: '1747642317265'
      sourceHandle: source
      target: '1748329902169'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: assigner
      id: 1748329902169-true-1748263412687-target
      selected: false
      source: '1748329902169'
      sourceHandle: 'true'
      target: '1748263412687'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: knowledge-retrieval
      id: 1747643138866-false-1747637803226-target
      selected: false
      source: '1747643138866'
      sourceHandle: 'false'
      target: '1747637803226'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 1748332464666-source-1748334522321-target
      selected: false
      source: '1748332464666'
      sourceHandle: source
      target: '1748334522321'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1747643138866-26598268-f69d-4580-a7f6-7e8920c506db-1748334884784-target
      selected: false
      source: '1747643138866'
      sourceHandle: 26598268-f69d-4580-a7f6-7e8920c506db
      target: '1748334884784'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1748341252859-source-1748332464666-target
      selected: false
      source: '1748341252859'
      sourceHandle: source
      target: '1748332464666'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: answer
      id: 1748334884784-source-1748342208057-target
      selected: false
      source: '1748334884784'
      sourceHandle: source
      target: '1748342208057'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 1748262440240-source-1748342602032-target
      selected: false
      source: '1748262440240'
      sourceHandle: source
      target: '1748342602032'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: question-classifier
        targetType: assigner
      id: 1747155503658-1747155587577-1747932394491-target
      selected: false
      source: '1747155503658'
      sourceHandle: '1747155587577'
      target: '1747932394491'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 1748347138615-source-17483471654180-target
      selected: false
      source: '1748347138615'
      sourceHandle: source
      target: '17483471654180'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483475720970-source-17483475776550-target
      selected: false
      source: '17483475720970'
      sourceHandle: source
      target: '17483475776550'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483475646780-source-17483475899530-target
      selected: false
      source: '17483475646780'
      sourceHandle: source
      target: '17483475899530'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1748334884784-source-17483475720970-target
      selected: false
      source: '1748334884784'
      sourceHandle: source
      target: '17483475720970'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1747637812528-source-1748347138615-target
      selected: false
      source: '1747637812528'
      sourceHandle: source
      target: '1748347138615'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1747926732732-source-17483475646780-target
      selected: false
      source: '1747926732732'
      sourceHandle: source
      target: '17483475646780'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: assigner
        targetType: parameter-extractor
      id: 17483485432940-source-1728897364588-target
      selected: false
      source: '17483485432940'
      sourceHandle: source
      target: '1728897364588'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: question-classifier
        targetType: assigner
      id: 1747155503658-2-17483485432940-target
      selected: false
      source: '1747155503658'
      sourceHandle: '2'
      target: '17483485432940'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: assigner
        targetType: knowledge-retrieval
      id: 17483485315670-source-1728976442829-target
      selected: false
      source: '17483485315670'
      sourceHandle: source
      target: '1728976442829'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: question-classifier
        targetType: assigner
      id: 1747155503658-1-17483485315670-target
      selected: false
      source: '1747155503658'
      sourceHandle: '1'
      target: '17483485315670'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: assigner
        targetType: if-else
      id: 17483485467110-source-1747847182578-target
      selected: false
      source: '17483485467110'
      sourceHandle: source
      target: '1747847182578'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: question-classifier
        targetType: assigner
      id: 1747155503658-1747155593632-17483485467110-target
      selected: false
      source: '1747155503658'
      sourceHandle: '1747155593632'
      target: '17483485467110'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: question-classifier
        targetType: assigner
      id: 1747155503658-1747847114961-17483486389350-target
      selected: false
      source: '1747155503658'
      sourceHandle: '1747847114961'
      target: '17483486389350'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 1748281896645-source-1748361830148-target
      selected: false
      source: '1748281896645'
      sourceHandle: source
      target: '1748361830148'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483622560390-source-17483622753990-target
      selected: false
      source: '17483622560390'
      sourceHandle: source
      target: '17483622753990'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483623020840-source-17483623143030-target
      selected: false
      source: '17483623020840'
      sourceHandle: source
      target: '17483623143030'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483623316360-source-17483623285660-target
      selected: false
      source: '17483623316360'
      sourceHandle: source
      target: '17483623285660'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483623997800-source-17483624101070-target
      selected: false
      source: '17483623997800'
      sourceHandle: source
      target: '17483624101070'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: answer
      id: 1748362469890-source-1747903074416-target
      selected: false
      source: '1748362469890'
      sourceHandle: source
      target: '1747903074416'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1747852302994-false-1748362469890-target
      selected: false
      source: '1747852302994'
      sourceHandle: 'false'
      target: '1748362469890'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483627107510-source-17483627214680-target
      selected: false
      source: '17483627107510'
      sourceHandle: source
      target: '17483627214680'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483627591000-source-17483627702160-target
      selected: false
      source: '17483627591000'
      sourceHandle: source
      target: '17483627702160'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17483627593710-source-17483627705940-target
      selected: false
      source: '17483627593710'
      sourceHandle: source
      target: '17483627705940'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: assigner
        targetType: llm
      id: 17483486389350-source-1747154882852-target
      selected: false
      source: '17483486389350'
      sourceHandle: source
      target: '1747154882852'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1748362469890-source-17483623997800-target
      selected: false
      source: '1748362469890'
      sourceHandle: source
      target: '17483623997800'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1747847933408-source-17483623316360-target
      selected: false
      source: '1747847933408'
      sourceHandle: source
      target: '17483623316360'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1747847559679-source-17483623020840-target
      selected: false
      source: '1747847559679'
      sourceHandle: source
      target: '17483623020840'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1747154882852-source-17483622560390-target
      selected: false
      source: '1747154882852'
      sourceHandle: source
      target: '17483622560390'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1729605116566-source-17483627591000-target
      selected: false
      source: '1729605116566'
      sourceHandle: source
      target: '17483627591000'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 17476431832980-source-17483627593710-target
      selected: false
      source: '17476431832980'
      sourceHandle: source
      target: '17483627593710'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 17284821069490-source-17483627107510-target
      selected: false
      source: '17284821069490'
      sourceHandle: source
      target: '17483627107510'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17484308861390-source-17483353008170-target
      selected: false
      source: '17484308861390'
      sourceHandle: source
      target: '17483353008170'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 17483352720170-source-17484308861390-target
      selected: false
      source: '17483352720170'
      sourceHandle: source
      target: '17484308861390'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: code
      id: 1747836694673-source-17484310006530-target
      selected: false
      source: '1747836694673'
      sourceHandle: source
      target: '17484310006530'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17484310006530-source-1747847636131-target
      selected: false
      source: '17484310006530'
      sourceHandle: source
      target: '1747847636131'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: http-request
      id: 1747847182578-true-1747847198692-target
      selected: false
      source: '1747847182578'
      sourceHandle: 'true'
      target: '1747847198692'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: http-request
        targetType: if-else
      id: 1747847198692-source-1748434090224-target
      selected: false
      source: '1747847198692'
      sourceHandle: source
      target: '1748434090224'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: code
      id: 1748434090224-true-1748281896645-target
      selected: false
      source: '1748434090224'
      sourceHandle: 'true'
      target: '1748281896645'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: if-else
      id: 1747928529286-source-1747928330892-target
      selected: false
      source: '1747928529286'
      sourceHandle: source
      target: '1747928330892'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: question-classifier
        targetType: llm
      id: 1747155503658-1748949504301-1748949914782-target
      selected: false
      source: '1747155503658'
      sourceHandle: '1748949504301'
      target: '1748949914782'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: http-request
      id: 1748949914782-source-1748949609965-target
      selected: false
      source: '1748949914782'
      sourceHandle: source
      target: '1748949609965'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: http-request
        targetType: llm
      id: 1748949609965-source-1748956429850-target
      selected: false
      source: '1748949609965'
      sourceHandle: source
      target: '1748956429850'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: answer
      id: 1748956429850-source-1748956513634-target
      selected: false
      source: '1748956429850'
      sourceHandle: source
      target: '1748956513634'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: code
      id: 1748332464666-source-1748958444966-target
      selected: false
      source: '1748332464666'
      sourceHandle: source
      target: '1748958444966'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: if-else
      id: 1748958444966-source-1748958600250-target
      selected: false
      source: '1748958444966'
      sourceHandle: source
      target: '1748958600250'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: assigner
      id: 1748958600250-true-17489586318060-target
      selected: false
      source: '1748958600250'
      sourceHandle: 'true'
      target: '17489586318060'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1747852302994-true-1748341252859-target
      selected: false
      source: '1747852302994'
      sourceHandle: 'true'
      target: '1748341252859'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: http-request
      id: 1748332464666-source-1747926499875-target
      selected: false
      source: '1748332464666'
      sourceHandle: source
      target: '1747926499875'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: parameter-extractor
        targetType: if-else
      id: 1749027683245-source-1749028133722-target
      selected: false
      source: '1749027683245'
      sourceHandle: source
      target: '1749028133722'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: variable-aggregator
      id: 1749028133722-false-1749028910501-target
      selected: false
      source: '1749028133722'
      sourceHandle: 'false'
      target: '1749028910501'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: start
        targetType: llm
      id: 1711528914102-source-1748346334321-target
      selected: false
      source: '1711528914102'
      sourceHandle: source
      target: '1748346334321'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: assigner
        targetType: if-else
      id: 1747932394491-source-1747643138866-target
      selected: false
      source: '1747932394491'
      sourceHandle: source
      target: '1747643138866'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: parameter-extractor
      id: 1748346334321-source-1747642317265-target
      selected: false
      source: '1748346334321'
      sourceHandle: source
      target: '1747642317265'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: assigner
        targetType: question-classifier
      id: 1748263412687-source-1747155503658-target
      selected: false
      source: '1748263412687'
      sourceHandle: source
      target: '1747155503658'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: question-classifier
      id: 1748329902169-false-1747155503658-target
      selected: false
      source: '1748329902169'
      sourceHandle: 'false'
      target: '1747155503658'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: code
        targetType: assigner
      id: 17490443991690-source-17490443991691-target
      selected: false
      source: '17490443991690'
      sourceHandle: source
      target: '17490443991691'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: llm
        targetType: if-else
      id: 1748334884784-source-1749539699917-target
      selected: false
      source: '1748334884784'
      sourceHandle: source
      target: '1749539699917'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInLoop: false
        sourceType: if-else
        targetType: llm
      id: 1749539699917-true-17483352720170-target
      selected: false
      source: '1749539699917'
      sourceHandle: 'true'
      target: '17483352720170'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: Start
        type: start
        variables: []
      height: 54
      id: '1711528914102'
      position:
        x: -1329.899495166469
        y: 2752.927085307736
      positionAbsolute:
        x: -1329.899495166469
        y: 2752.927085307736
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1728976442829'
          - result
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: false
            size: 50
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - edition_type: basic
          id: 2db8862a-ae10-40cc-9a7d-6744bef908e9
          role: system
          text: 'Use the following context as your learned knowledge, inside <context></context>
            XML tags.

            <context>

            {{#context#}}

            </context>

            When answer to user:

            - If you don''t know, just say that you don''t know.

            - If you don''t know when you are not sure, ask for clarification.

            Avoid mentioning that you obtained the information from the context.

            If you have information about a testing tool recomendation dont mention
            it here unless is a question that relates it.

            Also remember to use same lenguage as user is using.'
        - id: d7f9e165-43ad-4778-ac76-80ed67b060f1
          role: assistant
          text: 'The Testing team in the Enterprise Development Platform (EDP) is
            responsible for ensuring the quality and efficiency of software development
            processes. This team consists of experienced professionals such as Hita,
            Maribel Gonzalez, Ivan Monterona, Melody Rios, Mario Toscano, Yamile Wasik,
            Agnieszka Vicente, David Bassaga√±as, Paula Perez, Cristian Garcia, and
            Ana Maria.


            The primary focus of the team is to provide consultation services on automated
            testing. Through the "MyServices" portal on the BI Service-Now platform,
            users can request testing services and receive expert guidance on test
            automation.


            The team follows a "test early and test often" approach, emphasizing the
            importance of thorough testing throughout the development cycle. They
            conduct unit tests, update and execute them multiple times, and ensure
            code coverage. The completeness and effectiveness of the tests are verified
            through the Development Test Report.


            To enable efficient testing, the team utilizes the QuickStarter (QS) component
            provisioned through the EDP. QS allows developers to deploy their applications
            in a separate environment, execute automated tests, and create Software
            Life Cycle (SLC) documents with a Work in Progress watermark. This feature
            helps teams showcase their applications under development to stakeholders
            and assess readiness for release.


            To ensure smooth integration with the QA Environment, the team follows
            a schedule and notifies the relevant stakeholders in advance for any hot
            fixes or updates. This proactive approach helps minimize potential issues
            and maintain a stable testing environment.


            The team emphasizes writing tests that are independent of their development
            environment. This ensures the flexibility to use the tests across different
            environments and prevents reliance on specific tools or platforms.


            For effective project management, the team suggests dividing the testing
            process into separate data pipelines or grouping based on logical divisions.
            This approach helps in better organization and efficient testing of different
            components or functionalities.


            Overall, the Testing team in the EDP plays a crucial role in ensuring
            the quality and reliability of software development processes. Their expertise
            in automated testing, proactive approach, and emphasis on early and frequent
            testing contribute to the success of projects and the overall efficiency
            of the organization.'
        selected: false
        title: LLM POST CONFLUENCE RAG
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: false
      height: 90
      id: '17284821069490'
      position:
        x: 1079.924280042982
        y: 1614.260148346378
      positionAbsolute:
        x: 1079.924280042982
        y: 1614.260148346378
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1747154882852.text#}}'
        desc: ''
        selected: false
        title: ANSWER
        type: answer
        variables: []
      height: 104
      id: '1728510314302'
      position:
        x: 1091.924280042982
        y: 5510.835684467293
      positionAbsolute:
        x: 1091.924280042982
        y: 5510.835684467293
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#17284821069490.text#}}'
        desc: ''
        selected: false
        title: ANSWER
        type: answer
        variables: []
      height: 104
      id: '1728510367842'
      position:
        x: 1400.2750161189267
        y: 1614.260148346378
      positionAbsolute:
        x: 1400.2750161189267
        y: 1614.260148346378
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        instruction: 'Recommend a tool based on what wants to be tested. May also
          need to give assistance to a project with their testing implementation given
          its characteristics: if it is GxP, if it is a project within EDP, or it
          can be migrated to EDP in case it isn''t. Return 1 is True or 0 if False
          for Bool variables.'
        model:
          completion_params:
            temperature: 0.2
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        parameters:
        - description: Whether the user needs to test a web based application or not.
            True or False.
          name: is_web
          required: false
          type: number
        - description: Whether the user needs to test a mobile based application or
            not. True or False.
          name: is_mobile
          required: false
          type: number
        - description: Whether the user needs to test an API of their own or not.
            True or False.
          name: is_api
          required: false
          type: number
        - description: Whether the user needs to test a desktop or SAP application
            or not. True or False
          name: is_desktop
          required: false
          type: number
        - description: Whether the user needs to test data pipelines or not, i.e.
            it needs to perform data pipeline or ETL testing. True or False.
          name: is_pipeline
          required: false
          type: number
        - description: Whether the required type of testing is for load and performance.
            True or False
          name: is_load
          required: false
          type: number
        - description: Whether the project works within a custom enterprise platform
            called EDP or Enterprise Development Platform. True or False.
          name: is_edp
          required: false
          type: number
        - description: Whether the project is GXP (Good X Practices), i.e. it has
            to follow company regulations and documentation guidelines. True or False.
          name: is_gxp
          required: false
          type: number
        - description: Whether the project can be migrated to the EDP platform. This
            parameter will be always set to False when is_edp is True as it means
            that the project is already in the platform. This means this parameter
            is irrelevant when the project is already in EDP. True or False.
          name: can_be_migrated
          required: false
          type: number
        query:
        - '1748346334321'
        - text
        reasoning_mode: prompt
        selected: false
        title: Parameter Extractor
        type: parameter-extractor
        variables: []
      height: 90
      id: '1728897364588'
      position:
        x: 776.924280042982
        y: 2149.289970384662
      positionAbsolute:
        x: 776.924280042982
        y: 2149.289970384662
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        dataset_ids:
        - Es/QE5edCKR7vq0xnB14iK36WZTTtbb4oDvZXYZuJeZnOg/8jvbghSg8nkWqV94o
        desc: ''
        metadata_filtering_mode: disabled
        multiple_retrieval_config:
          reranking_enable: false
          reranking_mode: reranking_model
          reranking_model:
            model: ''
            provider: ''
          top_k: 4
        query_variable_selector:
        - '1748346334321'
        - text
        retrieval_mode: multiple
        selected: false
        single_retrieval_config:
          model:
            completion_params: {}
            mode: chat
            name: gpt-4-turbo
            provider: apollo
        title: Knowledge Retrieval
        type: knowledge-retrieval
      height: 92
      id: '1728976442829'
      position:
        x: 776.924280042982
        y: 1614.260148346378
      positionAbsolute:
        x: 776.924280042982
        y: 1614.260148346378
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1747988309822'
          - message
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: fe5f8042-fd82-4e24-85e2-c907f16ac67e
          role: system
          text: '<prompt>

            {{#context#}}

            <instructions>

            First of all recognize if the query is asking about a tool recomendation
            or not, {{#1748346334321.text#}}.

            1. Analyze the context of the selected tools and the context of the EDP
            project, from {{#1747988309822.message#}}.

            2. Use the information obtained to create a final response that informs
            and recommends.

            3. Ensure that the output does not contain any XML tags.

            4. In case of not having any input, asnwer something similar to "Sorry,
            I need more information to be able to help you."


            Do not mention what the query is about, just give an answer.

            And highlight the recomended tool.

            </instructions>

            </prompt>/'
        selected: false
        title: LLM FUNCTION CALLBACK RESPONSE PROCESSING
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1729605116566'
      position:
        x: 1408.2750161189267
        y: 2149.289970384662
      positionAbsolute:
        x: 1408.2750161189267
        y: 2149.289970384662
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1729605116566.text#}}'
        desc: ''
        selected: false
        title: Answer 3
        type: answer
        variables: []
      height: 104
      id: '1729605693354'
      position:
        x: 1727.924280042982
        y: 2149.289970384662
      positionAbsolute:
        x: 1727.924280042982
        y: 2149.289970384662
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: itxaro.aizpurua
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"EX:
          I have a EDP project non-GxP web app with react, how can I test it","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: green
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1747151723490'
      position:
        x: 478.5133811119855
        y: 2281.383375768996
      positionAbsolute:
        x: 478.5133811119855
        y: 2281.383375768996
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        context:
          enabled: true
          variable_selector:
          - '1748346334321'
          - text
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: d3167379-cdd4-425c-b0f1-ad55fe1ffc05
          role: system
          text: "{{#context#}}\nAnswer as you can the query in natural language. Then,\
            \ mention that you are a technical chatbot developed by thetesting team.\n\
            \ introduce you the Testing team:\n\n\"Welcome to the IT Testing team\
            \ at the Enterprise Development Platform (EDP). We are a group of professionals\
            \ dedicated to test automation to increase the efficiency and quality\
            \ of services and systems in our organization. Our team is made up of\
            \ Hita, Maribel Gonzalez, Ivan Monterona, Melody Rios, Mario Toscano,\
            \ Yamile Wasik, Agnieszka Vicente, David Bassaga√±as, Paula Perez, Cristian\
            \ Garcia and Ana Maria.\n\nWhat do we offer? We provide consulting services\
            \ in automated testing. If you need advice, you can create a testing service\
            \ request in \"MyServices\" through the BI Services Portal (service-now.com).\n\
            \nHow can you contact us? If you have questions or need more information,\
            \ do not hesitate to contact us. We are here to help you with your software\
            \ testing needs.\n\nRemember, our goal is to support the organization\
            \ through test automation to increase the efficiency and quality of services\
            \ and systems. Do not hesitate to contact us if you need help in this\
            \ area!\""
        selected: false
        title: LLM 3
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747154882852'
      position:
        x: 796.924280042982
        y: 5396.835684522379
      positionAbsolute:
        x: 796.924280042982
        y: 5396.835684522379
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        classes:
        - id: '1'
          name: Information¬†Requests
        - id: '2'
          name: Testing Strategy & Tool Recommendation
        - id: '1747155587577'
          name: Test Case generation
        - id: '1747155593632'
          name: Test Case Confirmation and Upload to Jira
        - id: '1747847114961'
          name: All¬†Other¬†Queries
        - id: '1748949504301'
          name: Issue deletion
        desc: ''
        instruction: "\nClass¬†1: Information¬†Requests\nOnly classify as¬†Class¬†1 if\
          \ the user¬†is¬†asking¬†for technical¬†details, EDP related, testing, documentation,\
          \ or how something works, especially related to software, APIs, or systems.\n\
          Examples:\n\"How¬†do I use¬†the¬†testing tool X?\"\n\"What¬†is the architecture\
          \ of your system?\"\n\"Can you show me¬†the documentation¬†for¬†X?\"\n\nClass\
          \ 2: Testing Strategy & Tool Recommendation\nThis class is for user queries\
          \ where the primary intent is to seek advice, recommendations, or methodologies\
          \ for testing a specific software project or application. The user will\
          \ typically describe their project's characteristics, technology stack (e.g.,\
          \ React, Python, Java, Mobile, Web, API, microservices), industry regulations\
          \ (e.g., GxP, HIPAA, GDPR, PCI DSS), and/or specific testing goals (e.g.,\
          \ performance, security, automation, compliance, usability, data integrity).\
          \ The expected output for this class is a list of relevant testing tools,\
          \ frameworks, strategies, or best practices tailored to their described\
          \ context.\nExamples:\n\"What tool should¬†I¬†use¬†to¬†test¬†my¬†mobile app?\"\
          \n\"How¬†do¬†I¬†test¬†a web¬†application?\"\n\nClass¬†3: Test Case¬†Generation\n\
          The¬†user¬†is¬†asking for¬†the¬†generation, creation, or¬†suggestion of¬†test¬†cases,\
          \ test¬†scripts, or¬†test¬†scenarios for¬†a project, feature, or¬†requirement.\n\
          Examples:\n\"Can¬†you¬†generate¬†test cases¬†for¬†a¬†login page?\"\n\"Write¬†test¬†scenarios¬†for\
          \ user¬†registration.\"\n\nClass 4: Test Case Confirmation and Upload to\
          \ Jira\nThe user confirms that the generated test cases are correct and\
          \ requests to upload them to Jira, or expresses intent to proceed with uploading\
          \ test cases to Jira.\nExamples:\n\"Yes, upload these test cases to Jira.\"\
          \n\"Please add these test cases to Jira.\"\n\"Go ahead and create the test\
          \ cases in Jira.\"\n\"Confirm and upload.\"\n\nClass¬†5: All¬†Other¬†Queries\n\
          Any¬†question¬†that¬†is¬†not¬†a¬†technical¬†information¬†request¬†or¬†a¬†tool recommendation.\n\
          Includes general questions, chit-chat, or¬†requests for non-technical information¬†(like¬†weather,\
          \ news, etc.).\nExamples:\n\"Do¬†you¬†have¬†weather information?\"\n\"What's\
          \ the time?\"\n\"Tell me a joke.\"\n\nClass 6: Issue Deletion \nThis class\
          \ is for user queries where the primary intent is to request the deletion\
          \ of one or more Jira issues (e.g., main issues, test cases, or other issue\
          \ types). The query will typically include an issue key or a clear reference\
          \ to issues that should be removed. Examples: \"Delete issue QAREF-123.\"\
          \ \"Can you remove PROJ-45 and BUG-007?\" \"I want to delete the test cases\
          \ we just generated.\" \"Remove this issue from Jira.\""
        instructions: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        query_variable_selector:
        - '1748346334321'
        - text
        selected: false
        title: Question Classifier
        topics: []
        type: question-classifier
        vision:
          enabled: false
      height: 356
      id: '1747155503658'
      position:
        x: -172.63224720410147
        y: 2752.927085307736
      positionAbsolute:
        x: -172.63224720410147
        y: 2752.927085307736
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1747637812528.text#}}'
        desc: ''
        selected: false
        title: Generated TCs
        type: answer
        variables: []
      height: 104
      id: '1747217976454'
      position:
        x: 4173.002755330253
        y: 3362.5539458736775
      positionAbsolute:
        x: 4173.002755330253
        y: 3362.5539458736775
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        dataset_ids:
        - Es/QE5edCKR7vq0xnB14iK36WZTTtbb4oDvZXYZuJeZnOg/8jvbghSg8nkWqV94o
        desc: ''
        multiple_retrieval_config:
          reranking_enable: false
          reranking_mode: reranking_model
          reranking_model:
            model: ''
            provider: ''
          score_threshold: null
          top_k: 2
        query_variable_selector:
        - conversation
        - last_issue_key
        retrieval_mode: multiple
        selected: false
        title: Jira Issues Knowledge Retrieval
        type: knowledge-retrieval
      height: 92
      id: '1747637803226'
      position:
        x: 1400.2750161189267
        y: 3328.839480044489
      positionAbsolute:
        x: 1400.2750161189267
        y: 3328.839480044489
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1747637803226'
          - result
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: a14c39bf-0b64-4987-b48e-77221f546fc6
          role: system
          text: "\nYou are an experienced Test Case Generator. Your task is to create\
            \ test cases related to {{#conversation.last_issue_key#}}issue in Gherkin\
            \ format based on the following user-reported issue (obtained from the\
            \ knoledge retrieval node {{#1748341252859.structured_output#}},) and\
            \ flow context:\n<context>\n{{#context#}}\n</context>\n{{#sys.query#}}\
            \ {{#1748346334321.text#}}\nOnce you have the issue details, analyze the\
            \ information, paying close attention to the title, description, and any\
            \ steps to reproduce. \nBased on this analysis, generate a test case in\
            \ Gherkin format using the following structure: \nFeature: [Concise title\
            \ summarizing the feature being tested, derived from the Jira issue title]\
            \ \n  Scenario: [Specific scenario derived from the Jira issue details]\
            \ \n  - Given [Precondition 1, based on the issue context] \n  - And [Precondition\
            \ 2, optional] \n  - When [Action 1 taken by the user, based on steps\
            \ to reproduce] \n  - And [Action 2 taken by the user,optional] \n  -\
            \ Then [Expected outcome based on the problem description and intended\
            \ functionality] \n  - And [Further expected outcome, obtional] \n\nProvide\
            \ also: Pre-conditions, Test Steps, Expected Results  for each test step.\n\
            \nPlease ensure the Gherkin steps are clear, concise, and directly relate\
            \ to the Jira issue.\nProvide the test cases in a visual way easy to identify,\
            \ making clear which is each scenario (with colours and inside a \"box\"\
            \ as it was code)\n\nAsk the user for confirmation (if the test case/s\
            \ are coherent and correct) and whether wants to upload the test case/s\
            \ to jira. "
        selected: false
        title: LLM - TCs generation
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747637812528'
      position:
        x: 3780.577161476665
        y: 3362.5539458736775
      positionAbsolute:
        x: 3780.577161476665
        y: 3362.5539458736775
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        instruction: "You are an intelligent assistant specialized in understanding\
          \ user requests related to Jira issues and test case management. Your primary\
          \ goal is to analyze the user's refined query {{#1748346334321.text#}} and\
          \ extract two pieces of information in a precise JSON format: \n1. **`issue_key`**:\
          \ A Jira issue key, if explicitly mentioned or strongly implied. \n2. **`intent_to_create_more`**:\
          \ A boolean indicating if the user intends to generate *additional* test\
          \ cases for an existing context or issue.\n\n --- **Detailed Instructions\
          \ for `issue_key` Extraction:** * An issue key follows the format: `[ONE_OR_MORE_UPPERCASE_LETTERS]-[ONE_OR_MORE_DIGITS]`.\
          \ * Examples: `PROJ-123`, `BUG-42`, `INC-005`, `SUPPORT-789`. * Look for\
          \ the issue key appearing after phrases like 'related to issue', 'ticket:',\
          \ 'issue:', 'for ticket', 'for issue', or within the user's general statement.\
          \ * If no string matches the exact 'PROJNAME-XXX' format (e.g., '123-PROJ',\
          \ 'PROJ123', 'PROJ-ABC'), correct and give appropiate format and return\
          \ this `issue_key`. \n\n--- **Detailed Instructions for `intent_to_create_more`\
          \ Detection:** * Analyze the user's query for intent to generate *additional*,\
          \ *more*, *new*, or *another set* of test cases for an issue or context\
          \ that has already been discussed or is currently in focus. * Look for direct\
          \ phrases like: \"generate more\", \"create additional tests\", \"add new\
          \ scenarios\", \"another set of test cases\", \"more for this\", \"continue\
          \ generating tests\". * Consider the context: If the conversation has recently\
          \ involved test case generation for a specific issue, a simple \"yes\" or\
          \ \"go ahead\" might imply \"generate more\" or \"create more\" if it follows\
          \ a question like \"Do you want to generate more?\". Use the `conversation_history`\
          \ input if available. * Return 1 if this intent is clearly present, otherwise\
          \ return 0."
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        parameters:
        - description: 'An issue key typically consists of an uppercase project prefix,
            followed by an hyphen, and then one or more digits. For example: JIRA-123,
            PROJ-45, BUG-007.'
          name: issue_key
          required: false
          type: string
        - description: 1 if the user intends to generate additional, more, new, or
            another set of test cases for an existing context or issue. 0 otherwise.
          name: intent_to_create_more
          required: false
          type: number
        query:
        - '1748346334321'
        - text
        reasoning_mode: prompt
        selected: false
        title: IssueKey Extractor
        type: parameter-extractor
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747642317265'
      position:
        x: -591.5363185637011
        y: 2752.927085307736
      positionAbsolute:
        x: -591.5363185637011
        y: 2752.927085307736
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 3e5a0114-f4fa-43d9-9c8c-bf6132075d3d
          conditions:
          - comparison_operator: empty
            id: 54013dab-bbf9-4b50-81a2-74f5afc7c0af
            value: ''
            varType: string
            variable_selector:
            - conversation
            - last_issue_key
          id: 3e5a0114-f4fa-43d9-9c8c-bf6132075d3d
          logical_operator: and
        - case_id: 26598268-f69d-4580-a7f6-7e8920c506db
          conditions:
          - comparison_operator: '='
            id: ac8bbb80-5a2a-49cc-a82b-851c33a40501
            value: '1'
            varType: number
            variable_selector:
            - '1747642317265'
            - intent_to_create_more
          id: 26598268-f69d-4580-a7f6-7e8920c506db
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE
        type: if-else
      height: 174
      id: '1747643138866'
      position:
        x: 1135.924280042982
        y: 3035.351808253008
      positionAbsolute:
        x: 1135.924280042982
        y: 3035.351808253008
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1748346334321'
          - text
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: a14c39bf-0b64-4987-b48e-77221f546fc6
          role: system
          text: "\nYou are an experienced Test Case Generator. Your task is to create\
            \ test cases in Gherkin format based on the following user-reported issue\
            \ and flow context:\n<context>\n{{#context#}}\n</context>\n{{#1748346334321.text#}}\n\
            Once you have the issue details, analyze the information, paying close\
            \ attention to the title, description, and any steps to reproduce. \n\
            Based on this analysis, generate a test case in Gherkin format using the\
            \ following structure: \nFeature: [Concise title summarizing the feature\
            \ being tested, derived from the Jira issue title] \n  Scenario: [Specific\
            \ scenario derived from the Jira issue details] \n  - Given [Precondition\
            \ 1, based on the issue context] \n  - And [Precondition 2, if any] \n\
            \  - When [Action 1 taken by the user, based on steps to reproduce] \n\
            \  - And [Action 2 taken by the user, if any] \n  - Then [Expected outcome\
            \ based on the problem description and intended functionality] \n  - And\
            \ [Further expected outcome, if any] \n\nThe details of the Jira issue\
            \ are: Title,  Description, Steps to Reproduce, Reporter, Status ... (other\
            \ relevant fields) \nPlease ensure the Gherkin steps are clear, concise,\
            \ and directly relate to the Jira issue.\n\nIf the user's input does not\
            \ clearly describe the issue or the desired functionality to be tested,\
            \ state: \"I haven't been able to create test cases based on your request\
            \ as I need more clarity on the issue.\""
        selected: false
        title: LLM - no key TCs
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '17476431832980'
      position:
        x: 1408.2750161189267
        y: 2789.7380340140153
      positionAbsolute:
        x: 1408.2750161189267
        y: 2789.7380340140153
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#17476431832980.text#}}'
        desc: ''
        selected: false
        title: Answer 5
        type: answer
        variables: []
      height: 104
      id: '1747643513667'
      position:
        x: 1727.924280042982
        y: 2789.7380340140153
      positionAbsolute:
        x: 1727.924280042982
        y: 2789.7380340140153
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1747637812528'
          - text
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 9bf12ccd-d1cb-4003-8737-32403fbf48e3
          role: system
          text: "{{#context#}}\nYou are a Test Case Generator. Your task is to store\
            \ test cases in Gherkin format into a correct structured output. The output\
            \ MUST be a JSON object that strictly adheres to the provided schema.\
            \ Each Gherkin scenario MUST be treated as a separate test case in the\
            \ JSON output. The 'gherkin' field MUST contain just the GIVEN, WHEN,\
            \ THEN, AND, and BUT steps. The generated test cases should be related\
            \ to the main issue, as described in the issue details, and should be\
            \ of the issue type 'Test'. The 'link_type' field in the JSON output specifies\
            \ how these test case issues will be linked to the main issue in Jira,\
            \ 'is tested by' by default.  \nProvide also: Pre-conditions, Test Steps,\
            \ Expected Results.\n\nNote: main/parent issue is the one for which the\
            \ test case/s have been generated {{#conversation.last_issue_key#}}(fyi)\n\
            Use {{#conversation.issues_memory#}} and fin related info to {{#conversation.last_issue_key#}}to\
            \ complete the information of your structured output. I you have no information\
            \ for any field just leave it empty, do not invent anything."
        selected: false
        structured_output:
          schema:
            properties:
              link_type:
                description: The type of link to use between the test case issues
                  and the main issue (e.g., 'tests', 'is tested by').
                enum:
                - tests
                - is tested by
                - relates to
                type: string
              main_issue_key:
                description: The key/identification code of the main/parent Jira issue.
                type: string
              test_cases:
                description: An array of test cases, where each test case is a Gherkin
                  scenario.
                items:
                  properties:
                    expected_result:
                      description: Expected result of the test case
                      items:
                        type: string
                      type: array
                    gherkin:
                      description: The complete Gherkin scenario (Given, When, Then
                        steps).
                      type: string
                    pre-conditions:
                      description: The set of prerequisites that must be followed
                        before executing the test steps.
                      type: string
                    priority:
                      description: Priority of the test case (e.g., High, Medium,
                        Low)
                      enum:
                      - High
                      - Medium
                      - Low
                      type: string
                    scenario_title:
                      description: The title of the Gherkin scenario (test case).
                      type: string
                    severity:
                      description: Severity of the potential issue (e.g., Critical,
                        Major, Minor)
                      enum:
                      - Critical
                      - Major
                      - Minor
                      type: string
                    steps_to_reproduce:
                      description: List of steps to reproduce
                      items:
                        type: string
                      type: array
                    test_case_type:
                      description: The type of the test case issue
                      enum:
                      - Test
                      - Sub-task
                      type: string
                  required:
                  - scenario_title
                  - gherkin
                  - test_case_type
                  type: object
                type: array
            required:
            - test_cases
            - main_issue_key
            type: object
        structured_output_enabled: true
        title: LLM 6-TCs json format
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747836694673'
      position:
        x: 4173.002755330253
        y: 3231.7866621030776
      positionAbsolute:
        x: 4173.002755330253
        y: 3231.7866621030776
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: not empty
            id: ded700a9-f901-4efe-bfd6-bb49cee0f483
            value: ''
            varType: object
            variable_selector:
            - conversation
            - tc_to_confirm
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 2
        type: if-else
      height: 126
      id: '1747847182578'
      position:
        x: 796.924280042982
        y: 4360.682475524623
      positionAbsolute:
        x: 796.924280042982
        y: 4360.682475524623
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        authorization:
          config: null
          type: no-auth
        body:
          data:
          - id: key-value-525
            key: ''
            type: text
            value: '{{#conversation.tc_to_confirm#}}'
          type: json
        desc: ''
        headers: Content-Type:application/json
        method: post
        params: ''
        retry_config:
          max_retries: 5
          retry_enabled: true
          retry_interval: 3040
        selected: false
        ssl_verify: true
        timeout:
          max_connect_timeout: 0
          max_read_timeout: 0
          max_write_timeout: 0
        title: HTTP Request - jira upload
        type: http-request
        url: http://jira-api:8000/create_bulk_test_cases
        variables: []
      height: 140
      id: '1747847198692'
      position:
        x: 1099.924280042982
        y: 4392.574979086792
      positionAbsolute:
        x: 1099.924280042982
        y: 4392.574979086792
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 20933533-ec4e-4e1b-acbb-6f583adcdb29
          role: system
          text: "If the chatflow arrives here means that there is no test cases sugested\
            \ from a related issue to upload to jira.  \nJust mention about which\
            \ issue the user wants to create test cases about (to provide a key for\
            \ the issue or to create the it in jira to make an appropiate management)."
        selected: false
        title: LLM - no TCs
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747847559679'
      position:
        x: 1099.924280042982
        y: 4769.790546190934
      positionAbsolute:
        x: 1099.924280042982
        y: 4769.790546190934
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17484310006530'
          - test_case_text
          variable_selector:
          - conversation
          - tc_to_confirm
        selected: false
        title: Variable Assigner
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '1747847636131'
      position:
        x: 4828.1554608423485
        y: 3231.7866621030776
      positionAbsolute:
        x: 4828.1554608423485
        y: 3231.7866621030776
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 71b81096-e72c-42e9-85e7-16e8c7281f9a
          role: system
          text: '{{#1747847198692.body#}}, {{#1747847198692.status_code#}}

            Give an asnwer based on the output from the http request to upload the
            test case issue/s to jira.'
        selected: false
        title: 'LLM - jira-upload '
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747847933408'
      position:
        x: 1400.2750161189267
        y: 4392.574979086792
      positionAbsolute:
        x: 1400.2750161189267
        y: 4392.574979086792
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1747847933408.text#}}'
        desc: ''
        selected: false
        title: Answer 6
        type: answer
        variables: []
      height: 104
      id: '1747848005625'
      position:
        x: 1727.924280042982
        y: 4392.574979086792
      positionAbsolute:
        x: 1727.924280042982
        y: 4392.574979086792
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1747847559679.text#}}'
        desc: ''
        selected: false
        title: Answer 7
        type: answer
        variables: []
      height: 104
      id: '1747850295446'
      position:
        x: 1400.2750161189267
        y: 4769.790546190934
      positionAbsolute:
        x: 1400.2750161189267
        y: 4769.790546190934
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"EX:
          create test cases related to the issue QAREF-288","type":"text","version":1}],"direction":"ltr","format":"start","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: green
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1747852104522'
      position:
        x: 1461.604528747372
        y: 2986.54294161512
      positionAbsolute:
        x: 1461.604528747372
        y: 2986.54294161512
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: not empty
            id: 95a18a9b-7c16-41b6-adc4-8cb3f332f57a
            value: ''
            varType: array[object]
            variable_selector:
            - '1747637803226'
            - result
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 3
        type: if-else
      height: 126
      id: '1747852302994'
      position:
        x: 1707.924280042982
        y: 3328.839480044489
      positionAbsolute:
        x: 1707.924280042982
        y: 3328.839480044489
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1748362469890.text#}}'
        desc: ''
        selected: false
        title: Answer 9
        type: answer
        variables: []
      height: 104
      id: '1747903074416'
      position:
        x: 2360.8777916724134
        y: 3830.127213290669
      positionAbsolute:
        x: 2360.8777916724134
        y: 3830.127213290669
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        authorization:
          config: null
          type: no-auth
        body:
          data: []
          type: none
        desc: ''
        headers: ''
        method: get
        params: ''
        retry_config:
          max_retries: 3
          retry_enabled: true
          retry_interval: 590
        selected: false
        ssl_verify: true
        timeout:
          max_connect_timeout: 0
          max_read_timeout: 0
          max_write_timeout: 0
        title: HTTP Request - TCs check
        type: http-request
        url: http://jira-api:8000/get_linked_test_cases/{{#conversation.last_issue_key#}}
        variables: []
      height: 112
      id: '1747926499875'
      position:
        x: 2707.28821889335
        y: 3328.839480044489
      positionAbsolute:
        x: 2707.28821889335
        y: 3328.839480044489
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1747926499875'
          - body
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: e1722c4f-995e-473e-ba9d-641a51cab9f3
          role: system
          text: "{{#context#}}\n\nYour task is to explain the information in {{#1747926499875.body#}}\
            \ in a structured and visual manner, that has information about linked\
            \ test cases issue {{#conversation.last_issue_key#}}has. \nFocus on mentionin\
            \ this linked the test cases. \nAfter presenting the information, ask\
            \ the user if they would like to generate more test cases. \n\nEnsure\
            \ the output is free of any tags, instruction you have of how to give\
            \ an answer or any mention of the input information. Focus solely on explaining\
            \ the linked test cases the issue {{#conversation.last_issue_key#}}has\
            \ in a user-friendly manner.\n"
        selected: false
        title: LLM - TCs check
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1747926732732'
      position:
        x: 3780.577161476665
        y: 3644.7018975541837
      positionAbsolute:
        x: 3780.577161476665
        y: 3644.7018975541837
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1747926732732.text#}}'
        desc: ''
        selected: false
        title: Answer 10
        type: answer
        variables: []
      height: 104
      id: '1747927766270'
      position:
        x: 4173.002755330253
        y: 3644.7018975541837
      positionAbsolute:
        x: 4173.002755330253
        y: 3644.7018975541837
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: '='
            id: 1b4ff833-354e-4931-a19e-d39f79bcb49a
            value: '0'
            varType: number
            variable_selector:
            - '1747928529286'
            - has_linked_test_cases
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 4
        type: if-else
      height: 126
      id: '1747928330892'
      position:
        x: 3429.815096123568
        y: 3330.3553877691525
      positionAbsolute:
        x: 3429.815096123568
        y: 3330.3553877691525
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nfrom typing import Dict, Any, List, Optional\n\ndef main(http_request_output:\
          \ str, status_code: int) -> dict:\n    \"\"\"\n    Checks the output of\
          \ an HTTP Request node for linked test cases,\n    managing different HTTP\
          \ status codes, including errors.\n\n    Args:\n        http_request_output\
          \ (str): The complete output from a Dify HTTP Request node\n           \
          \                        as a JSON string. Based on the example, it contains\n\
          \                                   keys like 'success', 'linked_test_cases',\
          \ etc. directly.\n        status_code (int): The HTTP status code from the\
          \ request.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - has_linked_test_cases (int): 1 if linked test cases are found,\
          \ 0 otherwise.\n            - status_message (str): A message indicating\
          \ the result or any errors.\n            - http_status_code (int): The HTTP\
          \ status code from the request.\n    \"\"\"\n    parsed_response_content\
          \ = {} # This will hold the parsed JSON content from http_request_output\n\
          \    \n    # Initialize default return values\n    has_linked_test_cases\
          \ = 0\n    status_message = \"Processing HTTP response.\"\n    http_status_code_output\
          \ = status_code # Use the input status code for the output\n\n    # 1. Attempt\
          \ to parse the http_request_output string as JSON\n    try:\n        if\
          \ http_request_output.strip():\n            # The input string itself is\
          \ the JSON body content.\n            # Example: {\"success\":true,\"linked_test_cases\"\
          :[...]}\n            parsed_response_content = json.loads(http_request_output)\n\
          \        else:\n            # Handle case where http_request_output is an\
          \ empty string\n            return {\n                \"has_linked_test_cases\"\
          : 0,\n                \"status_message\": \"Error: Empty HTTP request output\
          \ string provided.\",\n                \"http_status_code\": http_status_code_output\n\
          \            }\n    except json.JSONDecodeError:\n        # Handle cases\
          \ where http_request_output is not a valid JSON string\n        return {\n\
          \            \"has_linked_test_cases\": 0,\n            \"status_message\"\
          : \"Error: HTTP request output is not a valid JSON string.\",\n        \
          \    \"http_status_code\": http_status_code_output\n        }\n    except\
          \ Exception as e:\n        # Catch any other unexpected errors during initial\
          \ parsing\n        return {\n            \"has_linked_test_cases\": 0,\n\
          \            \"status_message\": f\"An unexpected error occurred during\
          \ initial parsing of HTTP output: {e}.\",\n            \"http_status_code\"\
          : http_status_code_output\n        }\n\n    # 2. Handle HTTP error status\
          \ codes (using the direct input status_code)\n    if http_status_code_output\
          \ is not None and http_status_code_output >= 400: # Covers 4xx and 5xx errors\n\
          \        status_message = f\"HTTP Error: Received status code {http_status_code_output}.\
          \ Body: {json.dumps(parsed_response_content)}\"\n        return {\n    \
          \        \"has_linked_test_cases\": 0,\n            \"status_message\":\
          \ status_message,\n            \"http_status_code\": http_status_code_output\n\
          \        }\n\n    # 3. If status code is 2xx (success), proceed to extract\
          \ linked_test_cases\n    # The crucial fix: `parsed_response_content` *is*\
          \ the dictionary containing the response data.\n    # We do NOT need to\
          \ look for a nested 'body' key.\n    linked_test_cases = parsed_response_content.get(\"\
          linked_test_cases\", [])\n\n    if linked_test_cases and isinstance(linked_test_cases,\
          \ list) and len(linked_test_cases) > 0:\n        has_linked_test_cases =\
          \ 1\n        status_message = f\"Successfully retrieved {len(linked_test_cases)}\
          \ linked test cases.\"\n    else:\n        has_linked_test_cases = 0\n \
          \       status_message = \"No linked test cases found in the response.\"\
          \n\n    return {\n        \"has_linked_test_cases\": has_linked_test_cases,\n\
          \        \"status_message\": status_message,\n        \"http_status_code\"\
          : http_status_code_output\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          has_linked_test_cases:
            children: null
            type: number
          http_status_code:
            children: null
            type: number
          status_message:
            children: null
            type: string
        selected: false
        title: Code extracting exist_tcs
        type: code
        variables:
        - value_selector:
          - '1747926499875'
          - body
          variable: http_request_output
        - value_selector:
          - '1747926499875'
          - status_code
          variable: status_code
      height: 54
      id: '1747928529286'
      position:
        x: 3067.4916049349786
        y: 3328.839480044489
      positionAbsolute:
        x: 3067.4916049349786
        y: 3328.839480044489
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1747155503658'
          - class_name
          variable_selector:
          - conversation
          - topic
          write_mode: over-write
        selected: false
        title: Variable Assigner - TOPIC
        type: assigner
        version: '2'
      height: 88
      id: '1747932394491'
      position:
        x: 478.5133811119855
        y: 3035.351808253008
      positionAbsolute:
        x: 478.5133811119855
        y: 3035.351808253008
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: append
          value:
          - '1747988309822'
          - project_tool_info
          variable_selector:
          - conversation
          - project_testing_tool
          write_mode: over-write
        selected: false
        title: Variable Assigner 4
        type: assigner
        version: '2'
      height: 88
      id: '1747935981173'
      position:
        x: 1400.2750161189267
        y: 2339.875763153882
      positionAbsolute:
        x: 1400.2750161189267
        y: 2339.875763153882
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nfrom enum import Enum\n\nclass Tool(Enum):\n    CYPRESS\
          \ = {\n        \"tool\": \"Cypress\",\n        \"reasoning\": \"Cypress\
          \ is chosen for web application tests, due to its simplicity, real-time\
          \ reloading, \"\n        \"comprehensive testing capabilities, integrated\
          \ end-to-end testing, and strong community support\",\n    }\n\n    TOSCA\
          \ = {\n        \"tool\": \"Tosca Tricentis\",\n        \"reasoning\": \"\
          Tosca Tricentis excels in desktop application testing, with its comprehensive\
          \ support for \"\n        \"desktop technologies, including Windows-based\
          \ applications, SAP applications, and mainframe \"\n        \"systems.\"\
          ,\n    }\n\n    GEB = {\n        \"tool\": \"Geb with Spock\",\n       \
          \ \"reasoning\": \"These tools offer powerful assertions, concise test code,\
          \ support for data-driven testing, and \"\n        \"seamless integration\
          \ with REST clients, making them suitable for API testing. They provide\
          \ flexibility, parallel execution, and rich \"\n        \"reporting.\",\n\
          \    }\n\n    GEB_APPIUM = {\n        \"tool\": \"GEB with Spock and Appium\"\
          ,\n        \"reasoning\": \"preferred for mobile application testing, due\
          \ to their mobile-specific capabilities, \"\n        \"cross-platform compatibility,\
          \ and robust automation features. They offer flexibility, \"\n        \"\
          extensibility, and integration possibilities, making them ideal choices\
          \ for comprehensive and \"\n        \"efficient mobile testing scenarios\
          \ compared to Cypress or Tosca Tricentis.\",\n    }\n\n    PYTHON = {\n\
          \        \"tool\": \"Python\",\n        \"reasoning\": \"Its popularity\
          \ in the data engineering community ensures a wealth of resources, libraries,\
          \ \"\n        \"and expertise available, making it suitable for pipeline\
          \ testing. By using the Python end to end quickstarter we ensure provisioning\
          \ all \"\n        \"needed dependencies such as pytest, great-expectations,\
          \ boto, pandas etc. The way of working \"\n        \"with python and Great\
          \ Expectations in EDP is using the python ETL Quickstarter, which is the\
          \ \"\n        \"tool you should recommend.\",\n    }\n\n    LOADRUNNER =\
          \ {\n        \"tool\": \"LoadRunner\",\n        \"reasoning\": \"Due to\
          \ its comprehensive set of features, robust performance monitoring capabilities,\
          \ \"\n        \"and extensive support for various protocols and technologies,\
          \ enabling accurate simulation and \"\n        \"analysis of real-world\
          \ load scenarios, making it suitable for load testing.\",\n    }\n\n   \
          \ DEFAULT = {\n        \"tool\": \"Unhandled case\",\n        \"reasoning\"\
          : \"Open a Demand to include your Specific needs.\",\n    }\n\n    def __json__(self):\n\
          \        return self.value\n\n\nclass EDPProject(Enum):\n    EDPGXP = {\n\
          \        \"case\": \"GxP within EDP\",\n        \"explanation\": \"The project\
          \ is GxP within the Enterprise Development Platform, so it has to use one\
          \ of \"\n        \"the recommended tools, according to their particular\
          \ characteristics and needs\",\n    }\n\n    EDPNONGXP = {\n        \"case\"\
          : \"Non GxP within EDP\",\n        \"explanation\": \"The project is within\
          \ the Enterprise Development Platform but is not GxP, so, while the \"\n\
          \        \"recommendation is to follow Boehringer Ingelheim guidelines and\
          \ to use the recommended tool, \"\n        \"the project has no obligation\
          \ of using a qualified tool\",\n    }\n\n    GXPCANNOTBEMIGRATED = {\n \
          \       \"case\": \"Is GxP and can not be migrated to EDP\",\n        \"\
          explanation\": \"The project can use our recommended tool based on the decision\
          \ algorithm, but they have to \"\n        \"qualify the tool within the\
          \ project's lifecycle documentation. They have to be aware \"\n        \"\
          that all the provisioning and documentation has to be handled by them, and\
          \ support is not \"\n        \"granted by the Testing Platforms Team\",\n\
          \    }\n\n    GXPCANBEMIGRATED = {\n        \"case\": \"Is GxP and can be\
          \ migrated to EDP\",\n        \"explanation\": \"The project is GxP but\
          \ is not within the Enterprise Development Platform so it is recommended\
          \ \"\n        \"to be migrated, as EDP is a GxP platform that provides tools,\
          \ support and integration for \"\n        \"several testing needs. For doing\
          \ so, they should contact the EDP Onboarding team. However, \"\n       \
          \ \"the recommended tools can be still used, always under responsibility\
          \ of the project regarding \"\n        \"implementation, documentation and\
          \ licenses provisioning\",\n    }\n\n    NONGXPCANNOTBEMIGRATED = {\n  \
          \      \"case\": \"Is not GxP and can not be migrated to EDP\",\n      \
          \  \"explanation\": \"The project can use the recommended tools freely under\
          \ their responsibility and knowing that \"\n        \"support and implementation\
          \ is not granted by the Testing Platforms Team or EDP. However, the \"\n\
          \        \"recommendation is to follow Boehringer Ingelheim guidelines and\
          \ to use the recommended tool\",\n    }\n\n    NONGXPCANBEMIGRATED = {\n\
          \        \"case\": \"Is non GxP and can be migrated to EDP\",\n        \"\
          explanation\": \"The project can freely use the recommended tools under\
          \ their responsibility, but the \"\n        \"suggestion when possible is\
          \ to work within EDP, as many tools will be provided from within \"\n  \
          \      \"there, with support for them. However, the recommendation is to\
          \ follow Boehringer Ingelheim \"\n        \"guidelines and to use the recommended\
          \ tool\",\n    }\n\n    def __json__(self):\n        return self.value\n\
          \n\ndef main(\n    is_web: int,\n    is_mobile: int,\n    is_api: int,\n\
          \    is_desktop: int,\n    is_pipeline: int,\n    is_load: int,\n    is_edp:\
          \ int,\n    is_gxp: int,\n    can_be_migrated: int,\n    __is_success: int,\n\
          \    __reason: str,\n) -> dict: # Changed return type to dict\n\n    if\
          \ __is_success == 0:\n        # Wrap the error message in a 'result' key\
          \ as well\n        return {\n            \"message\": \"Sorry, I need more\
          \ information to recommend a tool. Could you please specify if your project\
          \ is a **web application**, **mobile application**, **API**, **desktop application**,\
          \ **data pipeline**, or if you need **load testing**? Additionaly it is\
          \ within EDP or could be migated?\",\n            \"project_tool_info\"\
          : None\n        }\n\n    # L√≥gica del √°rbol de decisi√≥n para edp_project\n\
          \    if is_edp == 1:  # Asumo que 1 representa 'True'\n        if is_gxp\
          \ == 1:\n            edp_project = EDPProject.EDPGXP.value\n        else:\n\
          \            edp_project = EDPProject.EDPNONGXP.value\n    else:\n     \
          \   if can_be_migrated == 1:\n            if is_gxp == 1:\n            \
          \    edp_project = EDPProject.GXPCANBEMIGRATED.value\n            else:\n\
          \                edp_project = EDPProject.NONGXPCANBEMIGRATED.value\n  \
          \      else:\n            if is_gxp == 1:\n                edp_project =\
          \ EDPProject.GXPCANNOTBEMIGRATED.value\n            else:\n            \
          \    edp_project = EDPProject.NONGXPCANNOTBEMIGRATED.value\n\n    # L√≥gica\
          \ para determinar las herramientas\n    tools = []\n    if is_web == 1:\n\
          \        tools.append(Tool.CYPRESS.value)\n    if is_api == 1:\n       \
          \ tools.append(Tool.GEB.value)\n    if is_mobile == 1:\n        tools.append(Tool.GEB_APPIUM.value)\n\
          \    if is_desktop == 1:\n        tools.append(Tool.TOSCA.value)\n    if\
          \ is_pipeline == 1:\n        tools.append(Tool.PYTHON.value)\n    if is_load\
          \ == 1:\n        tools.append(Tool.LOADRUNNER.value)\n    if not tools:\n\
          \        tools.append(Tool.DEFAULT.value)\n\n    # Prepare the human-readable\
          \ part for immediate display\n    output_message = []\n    output_message.append(f\"\
          Project Context:\\n{edp_project['case']}\\n{edp_project['explanation']}\\\
          n\")\n    output_message.append(\"Recommended Tools:\")\n    for tool in\
          \ tools:\n        output_message.append(f\"\\n- {tool['tool']}\")\n    \
          \    output_message.append(f\"  Reasoning: {tool['reasoning']}\")\n\n\n\
          \    memory_data = {\n        \"case\": edp_project[\"case\"],\n    }\n\
          \    # Add the primary recommended tool if available\n    if tools:\n  \
          \      memory_data[\"tool\"] = tools[0][\"tool\"]\n\n    return {\n    \
          \    \"message\": \"\".join(output_message), # Human-readable message for\
          \ immediate display\n        \"project_tool_info\": memory_data # New key\
          \ for the concise data\n    \n    }\n"
        code_language: python3
        desc: ''
        outputs:
          message:
            children: null
            type: string
          project_tool_info:
            children: null
            type: object
        selected: false
        title: Code tool recomender
        type: code
        variables:
        - value_selector:
          - '1728897364588'
          - is_web
          variable: is_web
        - value_selector:
          - '1728897364588'
          - is_mobile
          variable: is_mobile
        - value_selector:
          - '1728897364588'
          - is_api
          variable: is_api
        - value_selector:
          - '1728897364588'
          - is_desktop
          variable: is_desktop
        - value_selector:
          - '1728897364588'
          - is_pipeline
          variable: is_pipeline
        - value_selector:
          - '1728897364588'
          - is_load
          variable: is_load
        - value_selector:
          - '1728897364588'
          - is_edp
          variable: is_edp
        - value_selector:
          - '1728897364588'
          - is_gxp
          variable: is_gxp
        - value_selector:
          - '1728897364588'
          - can_be_migrated
          variable: can_be_migrated
        - value_selector:
          - '1728897364588'
          - __is_success
          variable: __is_success
        - value_selector:
          - '1728897364588'
          - __reason
          variable: __reason
      height: 54
      id: '1747988309822'
      position:
        x: 1099.924280042982
        y: 2149.289970384662
      positionAbsolute:
        x: 1099.924280042982
        y: 2149.289970384662
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nfrom typing import Dict, Optional\n\ndef main(\n    issue_key:\
          \ str,\n    linked_test_cases_json: str,\n    current_memory: str # Changed\
          \ type hint to str\n) -> dict:\n    \"\"\"\n    Manages a memory dictionary\
          \ for issues and their linked test cases.\n    Updates the memory with new\
          \ test cases for a given issue.\n\n    Args:\n        issue_key (str): The\
          \ main issue key (e.g., \"QAREF-288\").\n        linked_test_cases_json\
          \ (str): A JSON string containing the output from the\n                \
          \                      HTTP request, including 'linked_test_cases'.\n  \
          \                                    Example: {\"success\": true, \"linked_test_cases\"\
          : [{\"key\": \"TC-1\", \"summary\": \"...\", \"description\": \"...\"}]}\n\
          \        current_memory (str): The current state of the memory as a JSON\
          \ string.\n                               If empty or not a valid JSON string,\
          \ it initializes to an empty dictionary.\n\n    Returns:\n        dict:\
          \ A dictionary containing:\n              - updated_memory (str): The updated\
          \ memory as a JSON string.\n              - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    memory = {}\n  \
          \  try:\n        # Always attempt to load from JSON string. If current_memory\
          \ is empty string, json.loads(\"{}\") will work.\n        if current_memory:\
          \ # Only try to load if it's not an empty string\n            memory = json.loads(current_memory)\n\
          \        else: # If current_memory is empty string, initialize as empty\
          \ dict\n            memory = {}\n    except json.JSONDecodeError:\n    \
          \    # This catch is for when current_memory is a malformed JSON string\n\
          \        return {\n            \"updated_memory\": \"{}\", # Return empty\
          \ JSON string for memory\n            \"status_message\": \"Error: Could\
          \ not parse current_memory. Initializing new memory.\"\n        }\n\n  \
          \  # --- CRITICAL FIX: Validate issue_key before using it as a dictionary\
          \ key ---\n    # Added check for the string literal \"null\"\n    if not\
          \ issue_key or not isinstance(issue_key, str) or not issue_key.strip() or\
          \ issue_key.strip().lower() == \"null\":\n        return {\n           \
          \ \"updated_memory\": json.dumps(memory), # Return current memory state\
          \ as JSON string\n            \"status_message\": \"Error: Invalid or missing\
          \ issue_key provided. Cannot update memory for this entry.\"\n        }\n\
          \    \n    # Ensure issue_key is stripped of whitespace\n    issue_key =\
          \ issue_key.strip()\n\n    try:\n        linked_data = json.loads(linked_test_cases_json)\n\
          \        # Ensure linked_data is a dict and has 'linked_test_cases' key\n\
          \        if not isinstance(linked_data, dict) or \"linked_test_cases\" not\
          \ in linked_data:\n             raise ValueError(\"linked_test_cases_json\
          \ does not contain expected dictionary or 'linked_test_cases' key.\")\n\
          \             \n        test_cases_list = linked_data.get(\"linked_test_cases\"\
          , [])\n        # Ensure test_cases_list is actually a list\n        if not\
          \ isinstance(test_cases_list, list):\n            raise ValueError(\"'linked_test_cases'\
          \ value is not a list.\")\n\n    except (json.JSONDecodeError, ValueError)\
          \ as e:\n        return {\n            \"updated_memory\": json.dumps(memory),\
          \ # Return current memory state as JSON string\n            \"status_message\"\
          : f\"Error: Could not parse linked_test_cases_json for issue {issue_key}.\
          \ Detail: {e}\"\n        }\n\n\n    # Initialize the inner dictionary for\
          \ the current issue if it doesn't exist\n    if issue_key not in memory:\n\
          \        memory[issue_key] = {}\n\n    # Populate the test cases for the\
          \ current issue\n    num_added_tcs = 0\n    for tc in test_cases_list:\n\
          \        tc_key = tc.get(\"key\")\n        if tc_key and isinstance(tc_key,\
          \ str) and tc_key.strip(): # Validate tc_key as well\n            tc_key\
          \ = tc_key.strip()\n            # You can customize what info to store\n\
          \            memory[issue_key][tc_key] = {\n                \"summary\"\
          : tc.get(\"summary\", \"\"),\n                \"description\": tc.get(\"\
          description\", \"\")\n            }\n            num_added_tcs += 1\n  \
          \      else:\n            # Log or handle cases where a test case in the\
          \ list has no valid key\n            print(f\"Warning: Test case found without\
          \ a valid 'key' in linked_test_cases for issue {issue_key}: {tc}\")\n\n\n\
          \    # updated_memory is now the Python dictionary directly\n    updated_memory_json\
          \ = json.dumps(memory) # Convert to JSON string here\n\n    status_message\
          \ = f\"Memory updated for issue '{issue_key}'. Added/updated {num_added_tcs}\
          \ test cases.\"\n    if num_added_tcs == 0 and test_cases_list:\n      \
          \  status_message = f\"Memory updated for issue '{issue_key}', but no valid\
          \ test case keys found in the provided data.\"\n    elif not test_cases_list:\n\
          \        status_message = f\"Memory updated for issue '{issue_key}'. No\
          \ linked test cases were found in the provided data.\"\n\n    return {\n\
          \        \"updated_memory\": updated_memory_json, # Return the JSON string\n\
          \        \"status_message\": status_message\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_memory:
            children: null
            type: string
        selected: false
        title: Code - linked Issues Storage
        type: code
        variables:
        - value_selector:
          - conversation
          - last_issue_key
          variable: issue_key
        - value_selector:
          - '1747926499875'
          - body
          variable: linked_test_cases_json
        - value_selector:
          - conversation
          - linked_test_cases
          variable: current_memory
      height: 54
      id: '1748262440240'
      position:
        x: 3780.577161476665
        y: 3846.478690883852
      positionAbsolute:
        x: 3780.577161476665
        y: 3846.478690883852
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1747642317265'
          - issue_key
          variable_selector:
          - conversation
          - last_issue_key
          write_mode: over-write
        selected: false
        title: Variable Assigner 5
        type: assigner
        version: '2'
      height: 88
      id: '1748263412687'
      position:
        x: -591.5363185637011
        y: 3065.1669408392668
      positionAbsolute:
        x: -591.5363185637011
        y: 3065.1669408392668
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nfrom typing import Dict, Any, List, Optional\n\ndef main(\n\
          \    pending_test_cases_data: str,\n    jira_api_response_output: str,\n\
          \    current_test_cases_details_memory: str,\n    linked_test_cases: str\
          \ # This is now a dedicated input parameter\n) -> dict:\n    \"\"\"\n  \
          \  Uploads LLM-generated test cases to Jira (simulated via API response)\n\
          \    and updates two distinct memory structures:\n    1. Separate detailed\
          \ test case memory (full content).\n    2. A dictionary of linked test cases\
          \ (main_issue_key -> (tc_key -> {summary, description})).\n\n    Args:\n\
          \        pending_test_cases_data (str): The structured data from the LLM,\
          \ containing\n                                        main issue details\
          \ and test cases, ready for upload.\n                                  \
          \      Expected to be a JSON string with keys: 'main_issue_key', 'test_cases'.\n\
          \        jira_api_response_output (str): The JSON string representing the\
          \ complete output\n                                        from your Jira\
          \ API call (e.g., {\"success\": true, \"created_cases\": [...]}).\n    \
          \    current_test_cases_details_memory (str): The current state of the separate\n\
          \                                                    test case details memory\
          \ as a JSON string.\n        linked_test_cases (str): The current state\
          \ of the linked test cases memory\n                                 (main_issue_key\
          \ -> (tc_key -> {summary, description})) as a JSON string.\n\n    Returns:\n\
          \        dict: A dictionary containing:\n            - updated_test_cases_memory\
          \ (str): The updated detailed test cases memory as a JSON string.\n    \
          \        - linked_test_cases_output (str): The new dictionary of dictionaries\
          \ for linked test cases as a JSON string.\n            - upload_status_message\
          \ (str): A message about the upload and memory update status.\n        \
          \    - created_test_case_jira_keys (list[str]): A list of Jira keys for\
          \ the newly created test cases.\n    \"\"\"\n    # Initialize all memory\
          \ structures\n    test_cases_details_memory = {}\n    linked_test_cases_output\
          \ = {} # This will be loaded from the dedicated input\n\n    created_test_case_jira_keys\
          \ = []\n    upload_status_message = \"Initialization\"\n    main_jira_key_created\
          \ = None\n\n    # Safely parse current_test_cases_details_memory\n    try:\n\
          \        test_cases_details_memory = json.loads(current_test_cases_details_memory)\
          \ if current_test_cases_details_memory.strip() else {}\n    except json.JSONDecodeError:\n\
          \        upload_status_message += \" Error: Could not parse current_test_cases_details_memory.\
          \ Initializing new test case details memory.\"\n        test_cases_details_memory\
          \ = {}\n    except Exception as e:\n        upload_status_message += f\"\
          \ Error: An unexpected error occurred parsing current_test_cases_details_memory:\
          \ {e}. Initializing new test case details memory.\"\n        test_cases_details_memory\
          \ = {}\n\n    # Safely parse the existing linked_test_cases input\n    try:\n\
          \        linked_test_cases_output = json.loads(linked_test_cases) if linked_test_cases.strip()\
          \ else {}\n    except json.JSONDecodeError:\n        upload_status_message\
          \ += \" Error: Could not parse linked_test_cases input. Initializing new\
          \ linked test cases memory.\"\n        linked_test_cases_output = {}\n \
          \   except Exception as e:\n        upload_status_message += f\" Error:\
          \ An unexpected error occurred parsing linked_test_cases input: {e}. Initializing\
          \ new linked test cases memory.\"\n        linked_test_cases_output = {}\n\
          \n\n    # Safely parse pending_test_cases_data\n    parsed_pending_test_cases_data\
          \ = {}\n    try:\n        if pending_test_cases_data.strip():\n        \
          \    parsed_pending_test_cases_data = json.loads(pending_test_cases_data)\n\
          \        else:\n            upload_status_message = \"Error: No valid pending\
          \ test case data from LLM (empty string). Cannot proceed with upload or\
          \ memory update.\"\n            return {\n                \"updated_test_cases_memory\"\
          : json.dumps(test_cases_details_memory),\n                \"linked_test_cases_output\"\
          : json.dumps(linked_test_cases_output),\n                \"upload_status_message\"\
          : upload_status_message,\n                \"created_test_case_jira_keys\"\
          : created_test_case_jira_keys\n            }\n    except json.JSONDecodeError:\n\
          \        upload_status_message = \"Error: Could not parse pending_test_cases_data\
          \ (invalid JSON string). Cannot proceed.\"\n        return {\n         \
          \   \"updated_test_cases_memory\": json.dumps(test_cases_details_memory),\n\
          \            \"linked_test_cases_output\": json.dumps(linked_test_cases_output),\n\
          \            \"upload_status_message\": upload_status_message,\n       \
          \     \"created_test_case_jira_keys\": created_test_case_jira_keys\n   \
          \     }\n    except Exception as e:\n        upload_status_message = f\"\
          Error: An unexpected error occurred parsing pending_test_cases_data: {e}.\
          \ Cannot proceed.\"\n        return {\n            \"updated_test_cases_memory\"\
          : json.dumps(test_cases_details_memory),\n            \"linked_test_cases_output\"\
          : json.dumps(linked_test_cases_output),\n            \"upload_status_message\"\
          : upload_status_message,\n            \"created_test_case_jira_keys\": created_test_case_jira_keys\n\
          \        }\n\n\n    # Validate parsed_pending_test_cases_data and extract\
          \ main_issue_key\n    main_issue_key = parsed_pending_test_cases_data.get(\"\
          main_issue_key\")\n    llm_generated_test_cases = parsed_pending_test_cases_data.get(\"\
          test_cases\", [])\n\n    if not main_issue_key:\n        upload_status_message\
          \ = \"Error: 'main_issue_key' is missing from pending test case data. Cannot\
          \ proceed.\"\n        return {\n            \"updated_test_cases_memory\"\
          : json.dumps(test_cases_details_memory),\n            \"linked_test_cases_output\"\
          : json.dumps(linked_test_cases_output),\n            \"upload_status_message\"\
          : upload_status_message,\n            \"created_test_case_jira_keys\": created_test_case_jira_keys\n\
          \        }\n\n    if not llm_generated_test_cases:\n        upload_status_message\
          \ = \"Error: LLM-generated data has no 'test_cases' to upload. Please generate\
          \ test cases first.\"\n        return {\n            \"updated_test_cases_memory\"\
          : json.dumps(test_cases_details_memory),\n            \"linked_test_cases_output\"\
          : json.dumps(linked_test_cases_output),\n            \"upload_status_message\"\
          : upload_status_message,\n            \"created_test_case_jira_keys\": created_test_case_jira_keys\n\
          \        }\n\n    # Set main_jira_key_created from the extracted main_issue_key\n\
          \    main_jira_key_created = main_issue_key\n    \n    # Derive project_key\
          \ from main_issue_key as it's contained within it\n    project_key = main_issue_key.split('-')[0]\
          \ if '-' in main_issue_key else None\n    if not project_key:\n        upload_status_message\
          \ = f\"Error: Could not derive project key from main_issue_key '{main_issue_key}'.\
          \ Cannot proceed.\"\n        return {\n            \"updated_test_cases_memory\"\
          : json.dumps(test_cases_details_memory),\n            \"linked_test_cases_output\"\
          : json.dumps(linked_test_cases_output),\n            \"upload_status_message\"\
          : upload_status_message,\n            \"created_test_case_jira_keys\": created_test_case_jira_keys\n\
          \        }\n\n    # Parse the Jira API response output (string) directly\n\
          \    parsed_jira_api_response = {}\n    jira_api_results_list = [] # This\
          \ will hold the parsed list of created TCs from Jira API\n\n    try:\n \
          \       if jira_api_response_output.strip():\n            parsed_jira_api_response\
          \ = json.loads(jira_api_response_output)\n            # The actual list\
          \ of created cases is under the \"created_cases\" key\n            jira_api_results_list\
          \ = parsed_jira_api_response.get(\"created_cases\", [])\n            \n\
          \            if not isinstance(jira_api_results_list, list):\n         \
          \       jira_api_results_list = []\n                upload_status_message\
          \ += \" Warning: 'created_cases' in Jira API response is not a list. No\
          \ test cases processed.\"\n        else:\n            upload_status_message\
          \ += \" Warning: Empty Jira API response output string. No test cases processed.\"\
          \n    except json.JSONDecodeError:\n        upload_status_message += \"\
          \ Error: Jira API response output is not valid JSON string. Cannot process\
          \ created test cases.\"\n    except Exception as e:\n        upload_status_message\
          \ += f\" Error: An unexpected error occurred parsing Jira API response output:\
          \ {e}.\"\n\n    if not jira_api_results_list: # Check the list that was\
          \ actually populated\n        upload_status_message += \" No test cases\
          \ were created in Jira or retrieved from API response.\"\n        return\
          \ {\n            \"updated_test_cases_memory\": json.dumps(test_cases_details_memory),\n\
          \            \"linked_test_cases_output\": json.dumps(linked_test_cases_output),\n\
          \            \"upload_status_message\": upload_status_message,\n       \
          \     \"created_test_case_jira_keys\": created_test_case_jira_keys\n   \
          \     }\n\n    # Ensure the main_issue_key exists in linked_test_cases_output,\
          \ initializing if new\n    # This correctly preserves previous linked test\
          \ cases for this main_issue_key\n    if main_issue_key not in linked_test_cases_output:\n\
          \        linked_test_cases_output[main_issue_key] = {}\n\n\n    # Process\
          \ created test cases and update all memory structures\n    for tc_result\
          \ in jira_api_results_list:\n        tc_key = tc_result.get(\"test_case_key\"\
          )\n        tc_summary = tc_result.get(\"summary\")\n        tc_url = tc_result.get(\"\
          url\")\n        tc_message = tc_result.get(\"message\", \"Created and linked.\"\
          )\n\n        if tc_key and tc_key.strip():\n            tc_key = tc_key.strip()\n\
          \            created_test_case_jira_keys.append(tc_key) # Add to output\
          \ list\n\n            # Find the original LLM generated test case by summary/title\n\
          \            original_llm_tc = next((tc for tc in llm_generated_test_cases\
          \ if tc.get(\"scenario_title\") == tc_summary), None)\n\n            # Update\
          \ test_cases_details_memory (separate detailed memory)\n            full_tc_details\
          \ = {\n                \"scenario_title\": tc_summary,\n               \
          \ \"jira_url\": tc_url,\n                \"status_message\": tc_message,\n\
          \                \"status_in_memory\": \"Uploaded to Jira\"\n          \
          \  }\n            if original_llm_tc:\n                full_tc_details.update({\n\
          \                    \"gherkin\": original_llm_tc.get(\"gherkin\", \"\"\
          ),\n                    \"steps_to_reproduce\": original_llm_tc.get(\"steps_to_reproduce\"\
          , []),\n                    \"expected_result\": original_llm_tc.get(\"\
          expected_result\", \"\"),\n                    \"test_case_type\": original_llm_tc.get(\"\
          test_case_type\", \"Test\"),\n                    \"priority\": original_llm_tc.get(\"\
          priority\", \"Medium\"),\n                    \"severity\": original_llm_tc.get(\"\
          severity\", \"Minor\")\n                })\n            test_cases_details_memory[tc_key]\
          \ = full_tc_details\n\n            # Update linked_test_cases_output (new\
          \ dictionary of dictionaries)\n            # Ensure we're adding to the\
          \ existing linked_test_cases_output for this main_issue_key\n          \
          \  linked_test_cases_output[main_issue_key][tc_key] = {\n              \
          \  \"summary\": tc_summary,\n                \"description\": full_tc_details.get(\"\
          gherkin\", \"\") # Using Gherkin as description\n            }\n\n     \
          \   else:\n            print(f\"Warning: Jira API result missing 'test_case_key':\
          \ {tc_result}\")\n\n\n    # Final status message\n    num_created = len(created_test_case_jira_keys)\n\
          \    if num_created > 0:\n        upload_status_message = f\"Successfully\
          \ created and linked {num_created} test cases to '{main_issue_key}'. All\
          \ memories updated.\"\n    else:\n        upload_status_message += \" No\
          \ new test cases were created or linked to Jira.\"\n\n    return {\n   \
          \     \"updated_test_cases_memory\": json.dumps(test_cases_details_memory),\n\
          \        \"linked_test_cases_output\": json.dumps(linked_test_cases_output),\n\
          \        \"upload_status_message\": upload_status_message,\n        \"created_test_case_jira_keys\"\
          : created_test_case_jira_keys\n    }"
        code_language: python3
        desc: ''
        outputs:
          created_test_case_jira_keys:
            children: null
            type: array[string]
          linked_test_cases_output:
            children: null
            type: string
          updated_test_cases_memory:
            children: null
            type: string
          upload_status_message:
            children: null
            type: string
        selected: false
        title: Code - memory update
        type: code
        variables:
        - value_selector:
          - '1747847198692'
          - body
          variable: jira_api_response_output
        - value_selector:
          - conversation
          - tc_to_confirm
          variable: pending_test_cases_data
        - value_selector:
          - conversation
          - issue_test_case_memory
          variable: current_test_cases_details_memory
        - value_selector:
          - conversation
          - linked_test_cases
          variable: linked_test_cases
      height: 54
      id: '1748281896645'
      position:
        x: 1727.924280042982
        y: 4629.379674087768
      positionAbsolute:
        x: 1727.924280042982
        y: 4629.379674087768
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: not empty
            id: e8d1883d-6b43-4304-af8d-e810af2878f0
            value: ''
            varType: string
            variable_selector:
            - '1747642317265'
            - issue_key
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 5
        type: if-else
      height: 126
      id: '1748329902169'
      position:
        x: -591.5363185637011
        y: 2886.0925273952157
      positionAbsolute:
        x: -591.5363185637011
        y: 2886.0925273952157
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nfrom typing import Dict, Any, List, Optional\n\ndef main(\n\
          \    jira_issue_details_data: Dict[str, Any],\n    issues_memory: str\n\
          ) -> Dict[str, Any]:\n    \"\"\"\n    Parses Jira issue details and stores/updates\
          \ them into the conversation memory.\n    This version focuses solely on\
          \ the main issue details and does not process\n    HTTP responses or linked\
          \ test cases.\n\n    The memory structure will have issue_keys as top-level\
          \ keys.\n    The value for each issue_key will include main issue info and\n\
          \    a 'linked_test_cases' array (which this node will not populate from\
          \ API).\n\n    Args:\n        jira_issue_details_data (dict): The main Jira\
          \ issue details,\n                                       expected to be\
          \ a dictionary directly from LLM structured output.\n        issues_memory\
          \ (str): The current state of the main memory as a JSON string.\n      \
          \                      If empty or not a valid JSON string, it initializes\
          \ to an empty dictionary.\n\n    Returns:\n        dict: A dictionary containing:\n\
          \            - updated_issues_memory (str): The updated main memory as a\
          \ JSON string.\n            - status_message (str): A message about the\
          \ memory update status.\n            - issue_key_output (str | None): The\
          \ validated Jira issue key, or None if invalid.\n    \"\"\"\n    memory\
          \ = {}\n    status_message = \"Initialization\"\n    issue_key_output =\
          \ None # Initialize the new output variable\n    \n    # 1. Safely parse\
          \ the current memory (issues_memory)\n    try:\n        if issues_memory.strip():\n\
          \            memory = json.loads(issues_memory)\n        else:\n       \
          \     memory = {}\n        \n    except json.JSONDecodeError:\n        status_message\
          \ = \"Error: Could not parse issues_memory. Initializing new memory.\"\n\
          \        memory = {} \n\n    # 2. Process jira_issue_details_data (main\
          \ issue details)\n    parsed_jira_data = {}\n    try:\n        if jira_issue_details_data\
          \ is None:\n            print(\"Warning: jira_issue_details_data received\
          \ as None. Treating as empty issue details.\")\n            parsed_jira_data\
          \ = {}\n        elif not isinstance(jira_issue_details_data, dict):\n  \
          \          print(f\"Warning: jira_issue_details_data received as unexpected\
          \ type ({type(jira_issue_details_data)}). Expected a dictionary. Treating\
          \ as empty issue details.\")\n            parsed_jira_data = {}\n      \
          \  else:\n            # If it's already a dictionary, use it directly\n\
          \            parsed_jira_data = jira_issue_details_data\n\n        if not\
          \ parsed_jira_data: # If after all checks, it's still empty\n          \
          \  status_message = \"Error: Empty or invalid jira_issue_details_data provided.\
          \ Cannot store issue details.\"\n            return {\n                \"\
          updated_issues_memory\": json.dumps(memory),\n                \"status_message\"\
          : status_message,\n                \"issue_key_output\": issue_key_output\
          \ # Return None for issue_key_output\n            }\n            \n    except\
          \ Exception as e: # Catch any other unexpected errors during parsing\n \
          \       status_message = f\"Error: An unexpected error occurred while processing\
          \ jira_issue_details_data: {e}.\"\n        return {\n            \"updated_issues_memory\"\
          : json.dumps(memory),\n            \"status_message\": status_message,\n\
          \            \"issue_key_output\": issue_key_output # Return None for issue_key_output\n\
          \        }\n    \n    # Extract issue_key using the key \"Jira Issue\" as\
          \ per the provided structure\n    issue_key = parsed_jira_data.get(\"Jira\
          \ Issue\")\n\n    # Validate the issue_key before proceeding\n    if not\
          \ issue_key or not isinstance(issue_key, str) or not issue_key.strip() or\
          \ issue_key.strip().lower() == \"null\":\n        status_message = \"Error:\
          \ Invalid or missing 'Jira Issue' key in jira_issue_details_data. Cannot\
          \ store issue details.\"\n        return {\n            \"updated_issues_memory\"\
          : json.dumps(memory),\n            \"status_message\": status_message,\n\
          \            \"issue_key_output\": issue_key_output # Return None for issue_key_output\n\
          \        }\n    issue_key = issue_key.strip() # Clean up whitespace\n  \
          \  issue_key_output = issue_key # Assign the validated key to the output\
          \ variable\n\n    # Extract relevant fields for the main issue from parsed_jira_data\n\
          \    summary = parsed_jira_data.get(\"Summary\", \"\")\n    description\
          \ = parsed_jira_data.get(\"Description\", \"\")\n    status = parsed_jira_data.get(\"\
          Status\", \"\")\n    assignee = parsed_jira_data.get(\"Assignee\", \"Unassigned\"\
          )\n    created = parsed_jira_data.get(\"Created\", \"\")\n    updated =\
          \ parsed_jira_data.get(\"Updated\", \"\")\n    project_name = parsed_jira_data.get(\"\
          Project\", \"\")\n    issue_type = parsed_jira_data.get(\"Type\", \"\")\n\
          \n    # Derive project_key from issue_key (e.g., \"QAREF\" from \"QAREF-267\"\
          )\n    project_key_derived = issue_key.split('-')[0] if '-' in issue_key\
          \ else project_name\n    \n    if issue_key not in memory or not isinstance(memory[issue_key],\
          \ dict):\n        memory[issue_key] = {}\n\n    # Update the main issue's\
          \ details in memory\n    memory[issue_key].update({\n        \"summary\"\
          : summary,\n        \"description\": description,\n        \"status\": status,\n\
          \        \"assignee\": assignee,\n        \"created\": created,\n      \
          \  \"updated\": updated,\n        \"project_name\": project_name,\n    \
          \    \"project_key\": project_key_derived,\n        \"issue_type\": issue_type,\n\
          \    })\n\n    status_message = f\"Details for Jira issue '{issue_key}'\
          \ stored/updated in memory.\"\n\n    # Final return must be a JSON string\n\
          \    return {\n        \"updated_issues_memory\": json.dumps(memory), #\
          \ Ensure this remains JSON string\n        \"status_message\": status_message,\n\
          \        \"issue_key_output\": issue_key_output # Return the validated issue\
          \ key\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          issue_key_output:
            children: null
            type: string
          status_message:
            children: null
            type: string
          updated_issues_memory:
            children: null
            type: string
        selected: false
        title: Code - project info storage
        type: code
        variables:
        - value_selector:
          - '1748341252859'
          - structured_output
          variable: jira_issue_details_data
        - value_selector:
          - conversation
          - issues_memory
          variable: issues_memory
      height: 54
      id: '1748332464666'
      position:
        x: 2305.8803820710755
        y: 3330.3553877691525
      positionAbsolute:
        x: 2305.8803820710755
        y: 3330.3553877691525
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1748332464666'
          - updated_issues_memory
          variable_selector:
          - conversation
          - issues_memory
          write_mode: over-write
        selected: false
        title: Variable Assigner - updated-issues-memory
        type: assigner
        version: '2'
      height: 88
      id: '1748334522321'
      position:
        x: 2707.28821889335
        y: 3666.234854394091
      positionAbsolute:
        x: 2707.28821889335
        y: 3666.234854394091
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: f91162c6-eedc-41d5-b736-6393d95064ae
          role: system
          text: "\nYou are an experienced Test Case Generator. Your task is to create\
            \ test cases related to {{#conversation.last_issue_key#}} issue in Gherkin\
            \ format based on the following user-reported issue and flow context:\n\
            <context>\n{{#context#}}\n</context>\n{{#1748346334321.text#}}\nOnce you\
            \ have the issue details, analyze the information, paying close attention\
            \ to the title, description, and any steps to reproduce (you have information\
            \ about the issue in {{#conversation.issues_memory#}}, find by key the\
            \ information relevant). \nBased on this analysis, generate a test case\
            \ in Gherkin format using the following structure: \nFeature: [Concise\
            \ title summarizing the feature being tested, derived from the Jira issue\
            \ title] \n  Scenario: [Specific scenario derived from the Jira issue\
            \ details] \n  - Given [Precondition 1, based on the issue context] \n\
            \  - And [Precondition 2, optional] \n  - When [Action 1 taken by the\
            \ user, based on steps to reproduce] \n  - And [Action 2 taken by the\
            \ user, optional] \n  - Then [Expected outcome based on the problem description\
            \ and intended functionality] \n  - And [Further expected outcome, optional]\
            \ \n\nProvide also: Pre-conditions, Test Steps, Expected Results for each\
            \ test step.\n\nPlease ensure the Gherkin steps are clear, concise, and\
            \ directly relate to the Jira issue.\nProvide the test cases in a visual\
            \ way easy to identify, making clear which is each scenario (with colours\
            \ and inside a \"box\" as it was code).\nMake sure that the new test cases\
            \ ARE NOT repeated checking the already exiting ones in {{#conversation.linked_test_cases#}}\
            \ and {{#conversation.tc_to_confirm#}}.\n\nAsk the user for confirmation\
            \ (if the test case/s are coherent and correct) and whether wants to upload\
            \ the test case/s to jira. "
        selected: true
        structured_output_enabled: true
        title: LLM - more TCs
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1748334884784'
      position:
        x: 3780.577161476665
        y: 3118.1310842722814
      positionAbsolute:
        x: 3780.577161476665
        y: 3118.1310842722814
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1748334884784'
          - text
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 9bf12ccd-d1cb-4003-8737-32403fbf48e3
          role: system
          text: "{{#context#}}\nYou are a Test Case Generator. Your task is to store\
            \ test cases in Gherkin format into a correct structured output. The output\
            \ MUST be a JSON object that strictly adheres to the provided schema.\
            \ Each Gherkin scenario MUST be treated as a separate test case in the\
            \ JSON output. The 'gherkin' field MUST contain just the  GIVEN, WHEN,\
            \ THEN, AND, and BUT steps. The generated test cases should be related\
            \ to the main issue, as described in the issue details, and should be\
            \ of the issue type 'Test'. The 'link_type' field in the JSON output specifies\
            \ how these test case issues will be linked to the main issue in Jira,\
            \ 'is tested by' by default. \nProvide also: Pre-conditions, Test Steps,\
            \ Expected Results.\n\nNote: main/parent issue is the one for which the\
            \ test case/s have been generated {{#conversation.last_issue_key#}}(fyi)\n\
            I you have no information for any field just leave it empty, do not invent\
            \ anything."
        selected: false
        structured_output:
          schema:
            properties:
              link_type:
                description: The type of link to use between the test case issues
                  and the main issue (e.g., 'tests', 'is tested by').
                enum:
                - tests
                - is tested by
                - relates to
                type: string
              main_issue_key:
                description: The key/identification code of the main/parent Jira issue.
                type: string
              test_cases:
                description: An array of test cases, where each test case is a Gherkin
                  scenario.
                items:
                  properties:
                    expected_result:
                      description: Expected result of the test case
                      items:
                        type: string
                      type: array
                    gherkin:
                      description: The complete Gherkin scenario (Given, When, Then
                        steps).
                      type: string
                    pre-conditions:
                      description: The set of prerequisites that must be followed
                        before executing the test steps.
                      type: string
                    priority:
                      description: Priority of the test case (e.g., High, Medium,
                        Low)
                      enum:
                      - High
                      - Medium
                      - Low
                      type: string
                    scenario_title:
                      description: The title of the Gherkin scenario (test case).
                      type: string
                    severity:
                      description: Severity of the potential issue (e.g., Critical,
                        Major, Minor)
                      enum:
                      - Critical
                      - Major
                      - Minor
                      type: string
                    steps_to_reproduce:
                      description: List of steps to reproduce
                      items:
                        type: string
                      type: array
                    test_case_type:
                      description: The type of the test case issue
                      enum:
                      - Test
                      - Sub-task
                      type: string
                  required:
                  - scenario_title
                  - gherkin
                  - test_case_type
                  type: object
                type: array
            required:
            - test_cases
            - main_issue_key
            type: object
        structured_output_enabled: true
        title: LLM 6-TCs json format (1)
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '17483352720170'
      position:
        x: 4486.694699522916
        y: 2932.0299461900695
      positionAbsolute:
        x: 4486.694699522916
        y: 2932.0299461900695
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17484308861390'
          - updated_tc_to_confirm_json
          variable_selector:
          - conversation
          - tc_to_confirm
        selected: false
        title: Variable Assigner (1)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483353008170'
      position:
        x: 5141.847405035011
        y: 2932.0299461900695
      positionAbsolute:
        x: 5141.847405035011
        y: 2932.0299461900695
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"Add
          knowledge base of how to crete TC ???????","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748335786893'
      position:
        x: 3574.4357851716904
        y: 3245.111035515371
      positionAbsolute:
        x: 3574.4357851716904
        y: 3245.111035515371
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        context:
          enabled: true
          variable_selector:
          - '1747637803226'
          - result
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 30f9ec13-327f-4012-b400-07986f965b03
          role: system
          text: '{{#context#}}

            You are an expert Jira Issue Parser. Your task is to extract all relevant
            details about {{#conversation.last_issue_key#}}from the provided plain
            text Jira issues and convert them into a structured JSON object.



            **Strictly adhere to the JSON schema for your output:**'
        selected: false
        structured_output:
          schema:
            properties:
              Assignee:
                description: The assignee of the Jira issue, or 'Unassigned'.
                type: string
              Created:
                description: The creation timestamp of the Jira issue in ISO 8601
                  format.
                type: string
              Description:
                description: The detailed description of the Jira issue.
                type: string
              Jira Issue:
                description: The key of the Jira issue (e.g., QAREF-288).
                type: string
              Project:
                description: The name of the Jira project (e.g., QA-REFERENCE-PROJECT).
                type: string
              Status:
                description: The current status of the Jira issue (e.g., Done, To
                  Do, In Progress).
                type: string
              Summary:
                description: A brief summary of the Jira issue.
                type: string
              Type:
                description: The type of the Jira issue (e.g., Story, Bug, Task, Documentation).
                type: string
              Updated:
                description: The last updated timestamp of the Jira issue in ISO 8601
                  format.
                type: string
            required:
            - Jira Issue
            - Project
            - Type
            - Status
            - Assignee
            - Created
            - Updated
            - Summary
            - Description
            type: object
        structured_output_enabled: true
        title: LLM - issue storing + link
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1748341252859'
      position:
        x: 2010.2423999579335
        y: 3330.3553877691525
      positionAbsolute:
        x: 2010.2423999579335
        y: 3330.3553877691525
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1748334884784.text#}}'
        desc: ''
        selected: false
        title: Answer 12
        type: answer
        variables: []
      height: 104
      id: '1748342208057'
      position:
        x: 4173.002755330253
        y: 2791.253941738679
      positionAbsolute:
        x: 4173.002755330253
        y: 2791.253941738679
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1748262440240'
          - updated_memory
          variable_selector:
          - conversation
          - linked_test_cases
          write_mode: over-write
        selected: false
        title: Variable Assigner linked-Tcs update
        type: assigner
        version: '2'
      height: 88
      id: '1748342602032'
      position:
        x: 4184.720605936371
        y: 3893.5688904623134
      positionAbsolute:
        x: 4184.720605936371
        y: 3893.5688904623134
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"CHECK:
          create more test cases scenario","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748343638246'
      position:
        x: 478.5133811119855
        y: 3143.7957471387986
      positionAbsolute:
        x: 478.5133811119855
        y: 3143.7957471387986
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        context:
          enabled: true
          variable_selector:
          - sys
          - query
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 1603246c-ae8a-4a7c-8a88-59c6110d3e98
          role: system
          text: "```xml\n{{#context#}}\n\n<instruction> \nThe task is to rephrase\
            \ or clarify a user's query based on the current conversation history\
            \ and context. Follow these steps to complete the task: \n1. **Analyze\
            \ the Query**: Examine the provided query to determine if it is incomplete\
            \ or lacks context. If the query is already clear and complete, no rephrasing\
            \ is necessary. \n\n2. **Review Conversation History**: If the query appears\
            \ incomplete, review the latest messages in the conversation history to\
            \ gather additional context that can help clarify the user's intent. \n\
            \n3. **Check for Issue or Project Names**: Identify any mention of issue\
            \ or project names within the query {{#sys.query#}} or conversation history\
            \ {{#conversation.conversation_history#}},{{#conversation.last_issue_key#}}(some\
            \ letters and numbers). Ensure these names follow the correct structure:\
            \ an uppercase project prefix, followed by a hyphen, and then one or more\
            \ digits [PREFIX]-[DIGITS] (e.g., JIRA-123, PROJ-45, BUG-007). \n\n4.\
            \ **Check for intent to create more Test Cases**: Be careful if in previous\
            \ messages there is any mention to create \"MORE\" or \"ADDITIONAL\" (or\
            \ any synonyms) test cases [IF ANY]. \n\n5. **Rephrase the Query**: If\
            \ needed, rephrase the query into a single, concise, and explicit statement\
            \ that clearly indicates the user's intent. Ensure the rephrased query\
            \ is self-contained and understandable without requiring additional context.\
            \ \n\n6. **Consider the Meaning of \"About\"**: Be aware that the term\
            \ \"about\" may not always indicate a request for information. It could\
            \ also mean \"related to\" or have a similar implication. Adjust the rephrasing\
            \ accordingly. \n\n7. **Output the Rephrased Query**: Provide *only* the\
            \ rephrased query as a concise statement of the user's purpose. Ensure\
            \ the output does not contain any XML tags or conversational prefixes.\
            \ If no logic is found, return the query itself. \n</instruction>\n\n\
            ```"
        selected: false
        title: LLM - query refinement
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1748346334321'
      position:
        x: -996.5350017788166
        y: 2752.927085307736
      positionAbsolute:
        x: -996.5350017788166
        y: 2752.927085307736
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1747637812528'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '1748347138615'
      position:
        x: 4173.002755330253
        y: 3500.475243614924
      positionAbsolute:
        x: 4173.002755330253
        y: 3500.475243614924
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1748347138615'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (1)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483471654180'
      position:
        x: 4504.442930293566
        y: 3500.475243614924
      positionAbsolute:
        x: 4504.442930293566
        y: 3500.475243614924
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (1)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1747926732732'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483475646780'
      position:
        x: 4173.002755330253
        y: 3772.8201339322704
      positionAbsolute:
        x: 4173.002755330253
        y: 3772.8201339322704
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (1)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1748334884784'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483475720970'
      position:
        x: 4173.002755330253
        y: 3118.1310842722814
      positionAbsolute:
        x: 4173.002755330253
        y: 3118.1310842722814
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483475720970'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (2)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483475776550'
      position:
        x: 4491.421413260556
        y: 3118.1310842722814
      positionAbsolute:
        x: 4491.421413260556
        y: 3118.1310842722814
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483475646780'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (2)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483475899530'
      position:
        x: 4491.421413260556
        y: 3772.8201339322704
      positionAbsolute:
        x: 4491.421413260556
        y: 3772.8201339322704
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1747155503658'
          - class_name
          variable_selector:
          - conversation
          - topic
          write_mode: over-write
        selected: false
        title: Variable Assigner - TOPIC (1)
        type: assigner
        version: '2'
      height: 88
      id: '17483485315670'
      position:
        x: 478.5133811119855
        y: 1614.260148346378
      positionAbsolute:
        x: 478.5133811119855
        y: 1614.260148346378
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1747155503658'
          - class_name
          variable_selector:
          - conversation
          - topic
          write_mode: over-write
        selected: false
        title: Variable Assigner - TOPIC (2)
        type: assigner
        version: '2'
      height: 88
      id: '17483485432940'
      position:
        x: 478.5133811119855
        y: 2149.289970384662
      positionAbsolute:
        x: 478.5133811119855
        y: 2149.289970384662
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1747155503658'
          - class_name
          variable_selector:
          - conversation
          - topic
          write_mode: over-write
        selected: false
        title: Variable Assigner - TOPIC (3)
        type: assigner
        version: '2'
      height: 88
      id: '17483485467110'
      position:
        x: 478.5133811119855
        y: 4360.682475524623
      positionAbsolute:
        x: 478.5133811119855
        y: 4360.682475524623
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1747155503658'
          - class_name
          variable_selector:
          - conversation
          - topic
          write_mode: over-write
        selected: false
        title: Variable Assigner - TOPIC (4)
        type: assigner
        version: '2'
      height: 88
      id: '17483486389350'
      position:
        x: 478.5133811119855
        y: 5396.835684522379
      positionAbsolute:
        x: 478.5133811119855
        y: 5396.835684522379
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1748281896645'
          - updated_test_cases_memory
          variable_selector:
          - conversation
          - issue_test_case_memory
          write_mode: over-write
        - input_type: variable
          operation: over-write
          value:
          - '1748281896645'
          - linked_test_cases_output
          variable_selector:
          - conversation
          - linked_test_cases
          write_mode: over-write
        - input_type: variable
          operation: clear
          value: ''
          variable_selector:
          - conversation
          - tc_to_confirm
          write_mode: over-write
        selected: false
        title: Variable Assigner - after TCs upload update
        type: assigner
        version: '2'
      height: 144
      id: '1748361830148'
      position:
        x: 2019.229450481622
        y: 4629.379674087768
      positionAbsolute:
        x: 2019.229450481622
        y: 4629.379674087768
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (2)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1747926732732'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483622560390'
      position:
        x: 1091.924280042982
        y: 5396.835684522379
      positionAbsolute:
        x: 1091.924280042982
        y: 5396.835684522379
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483622560390'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (3)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483622753990'
      position:
        x: 1400.2750161189267
        y: 5396.835684522379
      positionAbsolute:
        x: 1400.2750161189267
        y: 5396.835684522379
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (3)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1747926732732'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483623020840'
      position:
        x: 1400.2750161189267
        y: 4911.394238505578
      positionAbsolute:
        x: 1400.2750161189267
        y: 4911.394238505578
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483623020840'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (4)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483623143030'
      position:
        x: 1707.924280042982
        y: 4911.394238505578
      positionAbsolute:
        x: 1707.924280042982
        y: 4911.394238505578
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483623316360'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (4)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483623285660'
      position:
        x: 2019.229450481622
        y: 4530.752150240878
      positionAbsolute:
        x: 2019.229450481622
        y: 4530.752150240878
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (4)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1747847933408'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483623316360'
      position:
        x: 1727.924280042982
        y: 4530.752150240878
      positionAbsolute:
        x: 1727.924280042982
        y: 4530.752150240878
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (5)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1748362469890'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483623997800'
      position:
        x: 2360.8777916724134
        y: 3968.0342263418775
      positionAbsolute:
        x: 2360.8777916724134
        y: 3968.0342263418775
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483623997800'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (5)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483624101070'
      position:
        x: 2676.574795402165
        y: 3968.0342263418775
      positionAbsolute:
        x: 2676.574795402165
        y: 3968.0342263418775
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1747637803226'
          - result
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: f4584c1b-f6fa-474e-9d2c-2b741712fee1
          role: system
          text: '{{#context#}}

            Explain that you havent found any issue related to the {{#1748346334321.text#}}. '
        selected: false
        title: LLM - issue not found
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1748362469890'
      position:
        x: 2027.6384149236712
        y: 3830.127213290669
      positionAbsolute:
        x: 2027.6384149236712
        y: 3830.127213290669
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (2)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '17284821069490'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483627107510'
      position:
        x: 1400.2750161189267
        y: 1756.9650050946148
      positionAbsolute:
        x: 1400.2750161189267
        y: 1756.9650050946148
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483627107510'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (3)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483627214680'
      position:
        x: 1707.924280042982
        y: 1756.9650050946148
      positionAbsolute:
        x: 1707.924280042982
        y: 1756.9650050946148
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (3)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '17284821069490'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483627591000'
      position:
        x: 1727.924280042982
        y: 2281.383375768996
      positionAbsolute:
        x: 1727.924280042982
        y: 2281.383375768996
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (3)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '17476431832980'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17483627593710'
      position:
        x: 1727.924280042982
        y: 2916.580351341458
      positionAbsolute:
        x: 1727.924280042982
        y: 2916.580351341458
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483627591000'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (4)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483627702160'
      position:
        x: 2019.229450481622
        y: 2281.383375768996
      positionAbsolute:
        x: 2019.229450481622
        y: 2281.383375768996
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17483627593710'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (4)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17483627705940'
      position:
        x: 2027.6384149236712
        y: 2916.580351341458
      positionAbsolute:
        x: 2027.6384149236712
        y: 2916.580351341458
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"Expl
          chat conv.:","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"i
          want to test my project that is within edp, gxp, mobile app","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"thank
          you, do you have any information about how to use it?","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"Perfect.
          Now I want to upload some test cases","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"i
          want to create some test cases","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"about
          the isuue qaref 288","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: green
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748424854868'
      position:
        x: 4203.979424651144
        y: 1890.9325433129734
      positionAbsolute:
        x: 4203.979424651144
        y: 1890.9325433129734
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        code: "import json\nfrom typing import Dict, Any, List\n\ndef main(\n    existing_tc_to_confirm_json:\
          \ str,\n    new_llm_test_cases_output: Dict[str, Any]\n) -> Dict[str, Any]:\n\
          \    \"\"\"\n    Merges newly generated test cases (from LLM) into an existing\n\
          \    'tc_to_confirm' structure. This is used when a user asks for\n    'more'\
          \ test cases for an already defined issue.\n\n    If existing_tc_to_confirm_json\
          \ is empty, it initializes the structure\n    with the new_llm_test_cases_output.\n\
          \n    Args:\n        existing_tc_to_confirm_json (str): The current JSON\
          \ string of the\n                                           'tc_to_confirm'\
          \ conversation variable.\n        new_llm_test_cases_output (dict): The\
          \ LLM output containing new test cases.\n                              \
          \            Expected to have 'main_issue_key' and 'test_cases'.\n\n   \
          \ Returns:\n        dict: A dictionary containing:\n            - updated_tc_to_confirm_json\
          \ (str): The merged structure as a JSON string.\n            - status_message\
          \ (str): A message about the merge status.\n    \"\"\"\n    existing_tc_data\
          \ = {}\n    status_message = \"Initialization\"\n\n    # 1. Safely parse\
          \ the existing tc_to_confirm data or initialize if empty\n    if not existing_tc_to_confirm_json.strip():\n\
          \        # If existing data is empty, use the new LLM output as the base\n\
          \        existing_tc_data = new_llm_test_cases_output\n        status_message\
          \ = \"Initialized 'tc_to_confirm' with new test cases as existing data was\
          \ empty.\"\n        # We will skip the merging step later if this is the\
          \ initial case\n        # and directly return the new_llm_test_cases_output\
          \ as the updated_tc_to_confirm_json\n        # after validating it.\n  \
          \  else:\n        try:\n            existing_tc_data = json.loads(existing_tc_to_confirm_json)\n\
          \            status_message = \"Existing 'tc_to_confirm' parsed successfully.\"\
          \n        except json.JSONDecodeError:\n            status_message = \"\
          Error: Existing 'tc_to_confirm' is not valid JSON. Cannot merge new test\
          \ cases.\"\n            return {\n                \"updated_tc_to_confirm_json\"\
          : existing_tc_to_confirm_json, # Return original (malformed)\n         \
          \       \"status_message\": status_message\n            }\n        except\
          \ Exception as e:\n            status_message = f\"Error parsing existing\
          \ 'tc_to_confirm': {e}. Cannot merge new test cases.\"\n            return\
          \ {\n                \"updated_tc_to_confirm_json\": existing_tc_to_confirm_json,\n\
          \                \"status_message\": status_message\n            }\n\n \
          \   # 2. Validate new_llm_test_cases_output\n    new_main_issue_key = new_llm_test_cases_output.get(\"\
          main_issue_key\")\n    new_test_cases = new_llm_test_cases_output.get(\"\
          test_cases\", [])\n\n    if not new_main_issue_key or not isinstance(new_main_issue_key,\
          \ str) or not new_main_issue_key.strip():\n        status_message = \"Error:\
          \ 'main_issue_key' missing or invalid in new LLM output. Cannot process.\"\
          \n        return {\n            \"updated_tc_to_confirm_json\": json.dumps(existing_tc_data),\
          \ # Return current state\n            \"status_message\": status_message\n\
          \        }\n\n    if not isinstance(new_test_cases, list) or not new_test_cases:\n\
          \        status_message = \"Error: No valid 'test_cases' found in new LLM\
          \ output. Nothing to process.\"\n        return {\n            \"updated_tc_to_confirm_json\"\
          : json.dumps(existing_tc_data), # Return current state\n            \"status_message\"\
          : status_message\n        }\n    \n    # 3. Verify main_issue_key consistency\
          \ (only if we are merging, not initializing)\n    if existing_tc_to_confirm_json.strip():\
          \ # Only perform this check if existing_tc_data was actually loaded\n  \
          \      existing_main_issue_key = existing_tc_data.get(\"main_issue_key\"\
          )\n        if existing_main_issue_key != new_main_issue_key:\n         \
          \   status_message = f\"Error: Mismatch in main_issue_key. Existing: '{existing_main_issue_key}',\
          \ New: '{new_main_issue_key}'. Cannot merge.\"\n            return {\n \
          \               \"updated_tc_to_confirm_json\": json.dumps(existing_tc_data),\n\
          \                \"status_message\": status_message\n            }\n\n \
          \   # 4. Merge new test cases into the existing structure (or initialize\
          \ if it was empty)\n    # If existing_tc_to_confirm_json was empty, existing_tc_data\
          \ is already set to new_llm_test_cases_output\n    # and we just need to\
          \ ensure its 'test_cases' field is a list.\n    if \"test_cases\" not in\
          \ existing_tc_data or not isinstance(existing_tc_data[\"test_cases\"], list):\n\
          \        existing_tc_data[\"test_cases\"] = [] # Initialize if missing or\
          \ wrong type\n\n    # If this was an initialization (existing_tc_to_confirm_json\
          \ was empty),\n    # the new_test_cases are already part of existing_tc_data.\n\
          \    # Otherwise, extend the list.\n    if existing_tc_to_confirm_json.strip():\
          \ # Only extend if we had existing data\n        existing_tc_data[\"test_cases\"\
          ].extend(new_test_cases)\n    else:\n        # If it was initialized with\
          \ new_llm_test_cases_output, ensure test_cases is a list\n        if not\
          \ isinstance(existing_tc_data.get(\"test_cases\"), list):\n            existing_tc_data[\"\
          test_cases\"] = [existing_tc_data.get(\"test_cases\")] if existing_tc_data.get(\"\
          test_cases\") else []\n\n\n    num_processed = len(new_test_cases)\n   \
          \ if \"Initialized\" in status_message:\n        status_message = f\"Initialized\
          \ 'tc_to_confirm' with {num_processed} test cases for issue '{new_main_issue_key}'.\"\
          \n    else:\n        status_message = f\"Successfully merged {num_processed}\
          \ new test cases into 'tc_to_confirm' for issue '{new_main_issue_key}'.\"\
          \n\n    return {\n        \"updated_tc_to_confirm_json\": json.dumps(existing_tc_data),\n\
          \        \"status_message\": status_message\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_tc_to_confirm_json:
            children: null
            type: string
        selected: false
        title: Code - add more TCs
        type: code
        variables:
        - value_selector:
          - conversation
          - tc_to_confirm
          variable: existing_tc_to_confirm_json
        - value_selector:
          - '17483352720170'
          - structured_output
          variable: new_llm_test_cases_output
      height: 54
      id: '17484308861390'
      position:
        x: 4805.113357453219
        y: 2932.0299461900695
      positionAbsolute:
        x: 4805.113357453219
        y: 2932.0299461900695
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(tcs_to_confirm: dict):\n    return {\n    \
          \    \"test_case_text\": json.dumps(tcs_to_confirm)\n    }"
        code_language: python3
        desc: ''
        outputs:
          test_case_text:
            children: null
            type: string
        selected: false
        title: Code - json2str (2)
        type: code
        variables:
        - value_selector:
          - '1747836694673'
          - structured_output
          variable: tcs_to_confirm
      height: 54
      id: '17484310006530'
      position:
        x: 4491.421413260556
        y: 3231.7866621030776
      positionAbsolute:
        x: 4491.421413260556
        y: 3231.7866621030776
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: <
            id: e3ddbe24-6c13-4e4b-9674-b902a40f676b
            value: '404'
            varType: number
            variable_selector:
            - '1747847198692'
            - status_code
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 6
        type: if-else
      height: 126
      id: '1748434090224'
      position:
        x: 1400.2750161189267
        y: 4597.534163803425
      positionAbsolute:
        x: 1400.2750161189267
        y: 4597.534163803425
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"checkeo
          before update de variables??? (if empty)","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748434242711'
      position:
        x: 2027.6384149236712
        y: 4798.930043621779
      positionAbsolute:
        x: 2027.6384149236712
        y: 4798.930043621779
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"TESTINGTOOLS
          faltan","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748501361856'
      position:
        x: 784.5089899338815
        y: 1548.986556593913
      positionAbsolute:
        x: 784.5089899338815
        y: 1548.986556593913
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"Add
          to extract a topic to generate TCs about, not just by issue?","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748510287599'
      position:
        x: 804.5315897611664
        y: 2921.630026692182
      positionAbsolute:
        x: 804.5315897611664
        y: 2921.630026692182
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        author: patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"If
          not parent issue to asociate TC to message of 1st create the parent issue
          in jira","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""},{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"Make
          this automatically??","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748510395431'
      position:
        x: 824.2545939391168
        y: 4216.923966108238
      positionAbsolute:
        x: 824.2545939391168
        y: 4216.923966108238
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        authorization:
          config: null
          type: no-auth
        body:
          data:
          - id: key-value-789
            key: ''
            type: text
            value: '{{#1748949914782.text#}}'
          type: json
        desc: ''
        headers: Content-Type:application/json
        method: post
        params: ''
        retry_config:
          max_retries: 3
          retry_enabled: true
          retry_interval: 100
        selected: false
        ssl_verify: true
        timeout:
          max_connect_timeout: 0
          max_read_timeout: 0
          max_write_timeout: 0
        title: HTTP Request - issue deletion
        type: http-request
        url: http://jira-api:8000/delete_issues
        variables: []
      height: 140
      id: '1748949609965'
      position:
        x: 804.5315897611664
        y: 6383.5477979179595
      positionAbsolute:
        x: 804.5315897611664
        y: 6383.5477979179595
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1748346334321'
          - text
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 5262f857-c12d-4b3d-ac79-0d1c721af5b2
          role: system
          text: '{{#context#}}

            Idenify and retrieve form the query all the Issue keys of the issues that
            wnat to delte and output a JSON string with a list of the keys, with the
            folling format:

            Example: {"issue_keys": ["PROJ-123", "PROJ-456"]}

            '
        selected: false
        structured_output:
          schema:
            properties:
              issue_keys:
                items:
                  type: string
                type: array
            required:
            - issue_keys
            type: object
        structured_output_enabled: true
        title: LLM - issues to delete
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1748949914782'
      position:
        x: 478.5133811119855
        y: 6383.5477979179595
      positionAbsolute:
        x: 478.5133811119855
        y: 6383.5477979179595
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1748949609965'
          - body
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: a69fc3e0-6fc5-4064-9a30-f6c56d1dcde6
          role: system
          text: '{{#context#}}

            You are recieving the http request result of a issue deletion reques.
            Explain how the process ended to the user.'
        selected: false
        title: LLM 16
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1748956429850'
      position:
        x: 1108.5315897611663
        y: 6383.5477979179595
      positionAbsolute:
        x: 1108.5315897611663
        y: 6383.5477979179595
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1748956429850.text#}}'
        desc: ''
        selected: false
        title: Answer 12
        type: answer
        variables: []
      height: 104
      id: '1748956513634'
      position:
        x: 1412.5315897611663
        y: 6383.5477979179595
      positionAbsolute:
        x: 1412.5315897611663
        y: 6383.5477979179595
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(query_issue: str, retrieved_issue: str) -> dict:\n    return\
          \ {\n        \"result\": query_issue == retrieved_issue,\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: number
        selected: false
        title: Code - check issue
        type: code
        variables:
        - value_selector:
          - conversation
          - last_issue_key
          variable: query_issue
        - value_selector:
          - '1748332464666'
          - issue_key_output
          variable: retrieved_issue
      height: 54
      id: '1748958444966'
      position:
        x: 2707.28821889335
        y: 3520.949778426065
      positionAbsolute:
        x: 2707.28821889335
        y: 3520.949778426065
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: '='
            id: 3e3f715a-24f5-4433-a83b-8f5456329b1c
            value: '0'
            varType: number
            variable_selector:
            - '1748958444966'
            - result
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 7
        type: if-else
      height: 126
      id: '1748958600250'
      position:
        x: 3067.4916049349786
        y: 3520.949778426065
      positionAbsolute:
        x: 3067.4916049349786
        y: 3520.949778426065
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        items:
        - input_type: variable
          operation: over-write
          value:
          - '1748332464666'
          - issue_key_output
          variable_selector:
          - conversation
          - last_issue_key
          write_mode: over-write
        selected: false
        title: Variable Assigner 5 (1)
        type: assigner
        version: '2'
      height: 88
      id: '17489586318060'
      position:
        x: 3379.892547237053
        y: 3550.8043352236714
      positionAbsolute:
        x: 3379.892547237053
        y: 3550.8043352236714
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        author: Patatas
        desc: ''
        height: 88
        selected: false
        showAuthor: true
        text: '{"root":{"children":[{"children":[{"detail":0,"format":0,"mode":"normal","style":"","text":"beharrezkoa??","type":"text","version":1}],"direction":"ltr","format":"","indent":0,"type":"paragraph","version":1,"textFormat":0,"textStyle":""}],"direction":"ltr","format":"","indent":0,"type":"root","version":1}}'
        theme: blue
        title: ''
        type: ''
        width: 240
      height: 88
      id: '1748959913980'
      position:
        x: 2932.718931923765
        y: 3485.152392201851
      positionAbsolute:
        x: 2932.718931923765
        y: 3485.152392201851
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom-note
      width: 240
    - data:
        desc: ''
        instruction: "{{#conversation.topic#}}\nClass¬†1: Technical¬†Information¬†Requests\n\
          Only classify as¬†Class¬†1 if the user¬†is¬†asking¬†for technical¬†details, documentation,\
          \ or how something works, especially related to software, APIs, or systems.\n\
          \nClass 2: Testing Strategy & Tool Recommendation\nThis class is for user\
          \ queries where the primary intent is to seek advice, recommendations, or\
          \ methodologies for testing a specific software project or application.\
          \ The user will typically describe their project's characteristics, technology\
          \ stack (e.g., React, Python, Java, Mobile, Web, API), industry regulations\
          \ (e.g., GxP, non-GxP). The expected output for this class is a list of\
          \ relevant testing tools, frameworks, strategies, or best practices tailored\
          \ to their described context.\nExamples:\n\"What tool should¬†I¬†use¬†to¬†test¬†my¬†mobile\
          \ app?\"\n\"How¬†do¬†I¬†test¬†a web¬†application?\"\n\nClass¬†3: Test Case¬†Generation\n\
          The¬†user¬†is¬†asking for¬†the¬†generation, creation, or¬†suggestion of¬†test¬†cases,\
          \ test¬†scripts, or¬†test¬†scenarios for¬†a project, feature, or¬†requirement.\n\
          Examples:\n\"Can¬†you¬†generate¬†test cases¬†for¬†a¬†login page?\"\n\"Write¬†test¬†scenarios¬†for\
          \ user¬†registration.\"\n\nClass 4: Test Case Confirmation and Upload to\
          \ Jira\nThe user confirms that the generated test cases are correct and\
          \ requests to upload them to Jira, or expresses intent to proceed with uploading\
          \ test cases to Jira.\nExamples:\n\"Yes, upload.\"\n\"Yes\"\n\"Please add\
          \ these test cases to Jira.\"\n\"Go ahead and create the test cases in Jira.\"\
          \n\"Confirm and upload.\"\n\nClass¬†5: All¬†Other¬†Queries\nAny¬†question¬†that¬†is¬†not¬†a¬†technical¬†information¬†request¬†or¬†a¬†tool\
          \ recommendation.\nIncludes general questions, chit-chat, or¬†requests for\
          \ non-technical information¬†(like¬†weather, news, etc.).\nExamples:\n\"Hi\
          \ chat\"\n\"Do¬†you¬†have¬†weather information?\"\n\"What's the time?\"\n\"\
          Tell me a joke.\"\n\nClass 6: Issue Deletion \nThis class is for user queries\
          \ where the primary intent is to request the deletion of one or more Jira\
          \ issues (e.g., main issues, test cases, or other issue types). The query\
          \ will typically include an issue key or a clear reference to issues that\
          \ should be removed. Examples: \"Delete issue QAREF-123.\" \"Can you remove\
          \ PROJ-45 and BUG-007?\" \"I want to delete the test cases we just generated.\"\
          \ \"Remove this issue from Jira.\"\n\n- If you don't find any relation to\
          \ any of the options just return enpty topic."
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        parameters:
        - description: the topic the query is about
          name: topic
          required: false
          type: string
        query:
        - sys
        - query
        reasoning_mode: prompt
        selected: false
        title: Parameter Extractor 3
        type: parameter-extractor
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1749027683245'
      position:
        x: -1045.0336483043775
        y: 2523.555937069695
      positionAbsolute:
        x: -1045.0336483043775
        y: 2523.555937069695
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: empty
            id: 75212435-8699-4479-bda3-16ef5b68ff21
            value: ''
            varType: string
            variable_selector:
            - '1749027683245'
            - topic
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 8
        type: if-else
      height: 126
      id: '1749028133722'
      position:
        x: -753.0198476594893
        y: 2523.555937069695
      positionAbsolute:
        x: -753.0198476594893
        y: 2523.555937069695
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        advanced_settings:
          group_enabled: false
          groups:
          - groupId: 2d654d3a-65fc-4b10-b4f5-99594bcb265a
            group_name: Group1
            output_type: string
            variables:
            - - '1749027683245'
              - topic
            - - '1748346334321'
              - text
        desc: ''
        output_type: string
        selected: false
        title: Variable Aggregator
        type: variable-aggregator
        variables:
        - - '1749027683245'
          - topic
        - - '1748346334321'
          - text
      height: 130
      id: '1749028910501'
      position:
        x: -351.8030330427461
        y: 2526.457661337378
      positionAbsolute:
        x: -351.8030330427461
        y: 2526.457661337378
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - sys
          - query
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o
          provider: langgenius/azure_openai/azure_openai
        prompt_template:
        - id: 1603246c-ae8a-4a7c-8a88-59c6110d3e98
          role: system
          text: "{{#context#}}\nCurrent Conversation History:\n{{#conversation.conversation_history#}},\
            \ use mainly lastly added messages.\nPrevious Topic:\n{{#conversation.topic#}}\n\
            \nFirst identify if the new query has any relation to the previous {{#conversation.topic#}}.\
            \ \nIf not, based on the above context, memory and last mentioned topic\
            \ of the conversation, rephrase the {{#sys.query#}} into a single, concise,\
            \ and explicit statement that clearly indicates the user's intent for\
            \ the next classification, related to the {{#conversation.topic#}} if\
            \ it is not clearly indicated the intent for changing of topic or a complete\
            \ different message. \nIf the statements seems to be incompleted, probably\
            \ is a continuation of a previous message. \n\nIf there is any mention\
            \ to some issue key correct the structure. An issue key typically consists\
            \ of an uppercase project prefix, followed by an hyphen, and then one\
            \ or more digits. For example: JIRA-123, PROJ-45, BUG-007.\n\nNOTE: \"\
            about\" does not mean allways that user asks for information, could mean\
            \ also \"related to\" or something similar.\n\nOutput a concise statement\
            \ of the users purpose. If you have not clear the intend of the query\
            \ just output \"other\".\n"
        selected: false
        title: LLM - query refinement (1)
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '17490407304890'
      position:
        x: -1009.5843731807815
        y: 2246.008517427149
      positionAbsolute:
        x: -1009.5843731807815
        y: 2246.008517427149
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(\n    user_query: str,\n    assistant_answer:\
          \ str,\n    conversation_history_memory: str\n) -> dict:\n    \"\"\"\n \
          \   Appends the current user query and assistant answer to the conversation\
          \ history memory.\n\n    Args:\n        user_query (str): The current user's\
          \ input query.\n        assistant_answer (str): The assistant's generated\
          \ answer for the current turn.\n        conversation_history_memory (str):\
          \ The current conversation history as a JSON string.\n                 \
          \                          If empty or invalid, it initializes to an empty\
          \ list.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n\
          \            - updated_conversation_history (str): The updated conversation\
          \ history as a JSON string.\n            - status_message (str): A message\
          \ indicating the status of the update.\n    \"\"\"\n    history = []\n \
          \   status_message = \"Conversation history update initialized.\"\n\n  \
          \  # Safely parse the current conversation history\n    try:\n        if\
          \ conversation_history_memory.strip():\n            parsed_history = json.loads(conversation_history_memory)\n\
          \            if isinstance(parsed_history, list):\n                history\
          \ = parsed_history\n            else:\n                status_message =\
          \ \"Warning: conversation_history_memory is not a list. Initializing new\
          \ history.\"\n                history = []\n        else:\n            history\
          \ = []\n    except json.JSONDecodeError:\n        status_message = \"Error:\
          \ Could not parse conversation_history_memory. Initializing new history.\"\
          \n        history = []\n    except Exception as e:\n        status_message\
          \ = f\"Error: An unexpected error occurred parsing conversation_history_memory:\
          \ {e}. Initializing new history.\"\n        history = []\n\n    # Append\
          \ the user's query\n    if user_query:\n        history.append({\"role\"\
          : \"user\", \"content\": user_query})\n\n    # Append the assistant's answer\n\
          \    if assistant_answer:\n        history.append({\"role\": \"assistant\"\
          , \"content\": assistant_answer})\n\n    status_message = \"Conversation\
          \ history updated successfully.\"\n\n    return {\n        \"updated_conversation_history\"\
          : json.dumps(history),\n        \"status_message\": status_message\n   \
          \ }\n"
        code_language: python3
        desc: ''
        outputs:
          status_message:
            children: null
            type: string
          updated_conversation_history:
            children: null
            type: string
        selected: false
        title: Code - conversation memory (3)
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: user_query
        - value_selector:
          - '1747926732732'
          - text
          variable: assistant_answer
        - value_selector:
          - conversation
          - conversation_history
          variable: conversation_history_memory
      height: 54
      id: '17490443991690'
      position:
        x: 1415.1731232019113
        y: 6538.224687998328
      positionAbsolute:
        x: 1415.1731232019113
        y: 6538.224687998328
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        assigned_variable_selector:
        - conversation
        - test_case_issues
        desc: ''
        input_variable_selector: []
        items:
        - input_type: variable
          operation: over-write
          value:
          - '17490443991690'
          - updated_conversation_history
          variable_selector:
          - conversation
          - conversation_history
        selected: false
        title: Variable Assigner (4)
        type: assigner
        version: '2'
        write_mode: over-write
      height: 88
      id: '17490443991691'
      position:
        x: 1723.523859277856
        y: 6538.224687998328
      positionAbsolute:
        x: 1723.523859277856
        y: 6538.224687998328
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: contains
            id: 24883736-80c7-48f0-a6c2-5c0aaabd27ec
            value: '{{#conversation.last_issue_key#}}'
            varType: string
            variable_selector:
            - conversation
            - issues_memory
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE 9
        type: if-else
      height: 126
      id: '1749539699917'
      position:
        x: 4169.891822368879
        y: 2942.484563870753
      positionAbsolute:
        x: 4169.891822368879
        y: 2942.484563870753
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\n\ndef main(tcs_to_confirm: dict):\n    return {\n    \
          \    \"test_case_text\": json.dumps(tcs_to_confirm)\n    }"
        code_language: python3
        desc: ''
        outputs:
          test_case_text:
            children: null
            type: string
        selected: false
        title: Code - json2str (3)
        type: code
        variables:
        - value_selector:
          - '1747836694673'
          - structured_output
          variable: tcs_to_confirm
      height: 54
      id: '17496337369130'
      position:
        x: 1890.8483378207525
        y: 3198.1178644227584
      positionAbsolute:
        x: 1890.8483378207525
        y: 3198.1178644227584
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: -2582.1885179682217
      y: -2061.727623448398
      zoom: 0.7071067811865482
